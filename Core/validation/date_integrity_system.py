#!/usr/bin/env python3
"""
MIRRALISM Date Integrity Validation System
Purpose: æ—¥ä»˜ã‚¨ãƒ©ãƒ¼ã®äºˆé˜²çš„æ¤œå‡ºãƒ»ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ 
Design: åˆ¶ç´„ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆè¨­è¨ˆã«ã‚ˆã‚‹å“è³ªä¿è¨¼

Created: 2025-06-07
Version: 1.0.0
"""

import json
import re
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
from dataclasses import dataclass


@dataclass
class DateValidationResult:
    """æ—¥ä»˜æ¤œè¨¼çµæœ"""
    is_valid: bool
    file_path: str
    detected_date: Optional[str]
    system_date: str
    deviation_days: Optional[int]
    severity: str
    recommendation: str


class MIRRALISMDateValidator:
    """MIRRALISMæ—¥ä»˜æ•´åˆæ€§æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.validation_log = self.project_root / "Data" / "validation" / "date_integrity.log"
        self.validation_log.parent.mkdir(parents=True, exist_ok=True)
        
        # æ—¥ä»˜åˆ¶ç´„è¨­å®š
        self.max_future_days = 1  # æœªæ¥æ—¥ä»˜è¨±å®¹ç¯„å›²ï¼ˆ1æ—¥ï¼‰
        self.max_past_days = 365  # éå»æ—¥ä»˜è¨±å®¹ç¯„å›²ï¼ˆ1å¹´ï¼‰
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.validation_log),
                logging.StreamHandler()
            ]
        )
        
        logging.info("ğŸ” MIRRALISM Date Integrity System initialized")
        
    def get_system_date(self) -> datetime:
        """æ­£ç¢ºãªã‚·ã‚¹ãƒ†ãƒ æ—¥ä»˜å–å¾—"""
        return datetime.now(timezone(timedelta(hours=9)))  # JST
        
    def extract_dates_from_json(self, file_path: Path) -> List[str]:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¥ä»˜æ–‡å­—åˆ—ã‚’æŠ½å‡º"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ISO 8601å½¢å¼ã®æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³
            date_pattern = r'"(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}[+-]\d{2}:\d{2})"'
            dates = re.findall(date_pattern, content)
            
            return dates
            
        except Exception as e:
            logging.error(f"Failed to extract dates from {file_path}: {e}")
            return []
            
    def validate_date_string(self, date_str: str) -> Tuple[bool, Optional[datetime]]:
        """æ—¥ä»˜æ–‡å­—åˆ—ã®å¦¥å½“æ€§æ¤œè¨¼"""
        try:
            # ISO 8601å½¢å¼ã®è§£æ
            parsed_date = datetime.fromisoformat(date_str)
            return True, parsed_date
        except ValueError:
            return False, None
            
    def check_date_constraints(self, parsed_date: datetime, system_date: datetime) -> Dict[str, any]:
        """æ—¥ä»˜åˆ¶ç´„ãƒã‚§ãƒƒã‚¯"""
        delta = (parsed_date - system_date).days
        
        result = {
            "deviation_days": delta,
            "is_future": delta > 0,
            "is_past": delta < 0,
            "within_future_limit": delta <= self.max_future_days,
            "within_past_limit": delta >= -self.max_past_days,
            "severity": "NORMAL"
        }
        
        # é‡å¤§åº¦åˆ¤å®š
        if delta > self.max_future_days:
            result["severity"] = "CRITICAL"  # æœªæ¥æ—¥ä»˜
        elif delta < -self.max_past_days:
            result["severity"] = "HIGH"      # å¤ã™ãã‚‹æ—¥ä»˜
        elif abs(delta) > 30:
            result["severity"] = "MEDIUM"    # 1ãƒ¶æœˆä»¥ä¸Šã®å·®ç•°
        elif abs(delta) > 7:
            result["severity"] = "LOW"       # 1é€±é–“ä»¥ä¸Šã®å·®ç•°
            
        return result
        
    def validate_file(self, file_path: Path) -> List[DateValidationResult]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®å…¨æ—¥ä»˜ã‚’æ¤œè¨¼"""
        results = []
        system_date = self.get_system_date()
        
        dates = self.extract_dates_from_json(file_path)
        
        if not dates:
            # æ—¥ä»˜ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
            results.append(DateValidationResult(
                is_valid=False,
                file_path=str(file_path),
                detected_date=None,
                system_date=system_date.isoformat(),
                deviation_days=None,
                severity="WARNING",
                recommendation="No date fields found in JSON file"
            ))
            return results
            
        for date_str in dates:
            is_valid_format, parsed_date = self.validate_date_string(date_str)
            
            if not is_valid_format:
                results.append(DateValidationResult(
                    is_valid=False,
                    file_path=str(file_path),
                    detected_date=date_str,
                    system_date=system_date.isoformat(),
                    deviation_days=None,
                    severity="CRITICAL",
                    recommendation="Invalid date format detected"
                ))
                continue
                
            constraints = self.check_date_constraints(parsed_date, system_date)
            
            is_valid = (constraints["within_future_limit"] and 
                       constraints["within_past_limit"])
            
            recommendation = self._generate_recommendation(constraints)
            
            results.append(DateValidationResult(
                is_valid=is_valid,
                file_path=str(file_path),
                detected_date=date_str,
                system_date=system_date.isoformat(),
                deviation_days=constraints["deviation_days"],
                severity=constraints["severity"],
                recommendation=recommendation
            ))
            
        return results
        
    def _generate_recommendation(self, constraints: Dict) -> str:
        """æ¨å¥¨ä¿®æ­£ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        deviation = constraints["deviation_days"]
        severity = constraints["severity"]
        
        if severity == "CRITICAL":
            if constraints["is_future"]:
                return f"URGENT: Future date detected (+{deviation} days). Correct to current date."
            else:
                return f"URGENT: Extremely old date (-{abs(deviation)} days). Verify data integrity."
        elif severity == "HIGH":
            return f"Review date accuracy: {abs(deviation)} days deviation from current date."
        elif severity == "MEDIUM":
            return f"Consider date verification: {abs(deviation)} days deviation."
        elif severity == "LOW":
            return f"Minor date deviation: {abs(deviation)} days. Monitor for patterns."
        else:
            return "Date within acceptable range."
            
    def scan_directory(self, directory: Path, pattern: str = "*.json") -> List[DateValidationResult]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        all_results = []
        
        for file_path in directory.rglob(pattern):
            if file_path.is_file():
                file_results = self.validate_file(file_path)
                all_results.extend(file_results)
                
        return all_results
        
    def generate_validation_report(self, results: List[DateValidationResult]) -> Dict:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            "scan_timestamp": self.get_system_date().isoformat(),
            "total_files_scanned": len(set(r.file_path for r in results)),
            "total_dates_checked": len(results),
            "validation_summary": {
                "valid_dates": len([r for r in results if r.is_valid]),
                "invalid_dates": len([r for r in results if not r.is_valid]),
                "by_severity": {}
            },
            "critical_issues": [r for r in results if r.severity == "CRITICAL"],
            "high_priority_issues": [r for r in results if r.severity == "HIGH"],
            "recommendations": []
        }
        
        # é‡å¤§åº¦åˆ¥é›†è¨ˆ
        for severity in ["CRITICAL", "HIGH", "MEDIUM", "LOW", "NORMAL", "WARNING"]:
            count = len([r for r in results if r.severity == severity])
            report["validation_summary"]["by_severity"][severity] = count
            
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if report["critical_issues"]:
            report["recommendations"].append("ğŸš¨ Immediate action required for CRITICAL date errors")
        if report["high_priority_issues"]:
            report["recommendations"].append("âš ï¸ Review HIGH priority date inconsistencies")
            
        return report
        
    def fix_date_in_file(self, file_path: Path, old_date: str, new_date: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æ—¥ä»˜ã‚’è‡ªå‹•ä¿®æ­£"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æ—¥ä»˜æ–‡å­—åˆ—ã‚’ç½®æ›
            updated_content = content.replace(f'"{old_date}"', f'"{new_date}"')
            
            if content != updated_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(updated_content)
                    
                logging.info(f"âœ… Date fixed in {file_path}: {old_date} â†’ {new_date}")
                return True
            else:
                logging.warning(f"âš ï¸ No changes made to {file_path}")
                return False
                
        except Exception as e:
            logging.error(f"âŒ Failed to fix date in {file_path}: {e}")
            return False
            
    def auto_fix_critical_dates(self, results: List[DateValidationResult]) -> int:
        """CRITICALé‡å¤§åº¦ã®æ—¥ä»˜ã‚’è‡ªå‹•ä¿®æ­£"""
        fixed_count = 0
        system_date = self.get_system_date()
        
        for result in results:
            if result.severity == "CRITICAL" and result.detected_date:
                # ç¾åœ¨æ™‚åˆ»ã«è¿‘ã„é©åˆ‡ãªæ—¥ä»˜ã‚’ç”Ÿæˆ
                fixed_date = system_date.isoformat()
                
                if self.fix_date_in_file(Path(result.file_path), result.detected_date, fixed_date):
                    fixed_count += 1
                    
        return fixed_count


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    validator = MIRRALISMDateValidator()
    
    # PersonalityLearningãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
    scan_directory = validator.project_root / "Core" / "PersonalityLearning"
    
    logging.info(f"ğŸ” Starting date validation scan: {scan_directory}")
    
    results = validator.scan_directory(scan_directory)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = validator.generate_validation_report(results)
    
    # çµæœè¡¨ç¤º
    print("ğŸ” MIRRALISM Date Integrity Validation Report")
    print("=" * 55)
    print(f"ğŸ“… Scan Time: {report['scan_timestamp']}")
    print(f"ğŸ“ Files Scanned: {report['total_files_scanned']}")
    print(f"ğŸ”¢ Dates Checked: {report['total_dates_checked']}")
    print()
    print("ğŸ“Š Validation Summary:")
    print(f"  âœ… Valid Dates: {report['validation_summary']['valid_dates']}")
    print(f"  âŒ Invalid Dates: {report['validation_summary']['invalid_dates']}")
    print()
    print("ğŸš¨ Issues by Severity:")
    for severity, count in report['validation_summary']['by_severity'].items():
        if count > 0:
            icon = {"CRITICAL": "ğŸš¨", "HIGH": "âš ï¸", "MEDIUM": "ğŸ”¶", "LOW": "ğŸ”¸", "NORMAL": "âœ…", "WARNING": "âš¡"}
            print(f"  {icon.get(severity, 'ğŸ“Š')} {severity}: {count}")
    
    # é‡è¦ãªå•é¡Œã®è©³ç´°è¡¨ç¤º
    if report['critical_issues']:
        print("\nğŸš¨ Critical Issues Requiring Immediate Attention:")
        for issue in report['critical_issues']:
            print(f"  - {issue.file_path}: {issue.recommendation}")
            
    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    if report['recommendations']:
        print("\nğŸ’¡ Recommendations:")
        for rec in report['recommendations']:
            print(f"  {rec}")
            
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_path = validator.project_root / "Data" / "validation" / f"date_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
    print(f"\nğŸ“„ Detailed report saved: {report_path}")


if __name__ == "__main__":
    main()