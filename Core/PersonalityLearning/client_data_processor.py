#!/usr/bin/env python3
"""
MIRRALISM ClientDataProcessor - Phase 1 åŸºæœ¬å®Ÿè£…
============================================

ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’PersonalityLearningã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆã™ã‚‹åŸºæœ¬æ©Ÿèƒ½
17æ™‚é–“å®Ÿè£…ã‚¹ã‚³ãƒ¼ãƒ—ã§ã®æ¦‚å¿µå®Ÿè¨¼ãƒ¬ãƒ™ãƒ«å®Ÿè£…

Phase 1 æ©Ÿèƒ½ç¯„å›²:
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåŸºæœ¬æƒ…å ±ã®èª­ã¿è¾¼ã¿ãƒ»è§£æ
- PersonalityLearningçµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
- åŸºæœ¬çš„ãªåˆ†æãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
- çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚å¿µå®Ÿè¨¼

ä½œæˆè€…: MIRRALISM V2 æŠ€è¡“è€…
ä½œæˆæ—¥: 2025å¹´6æœˆ6æ—¥
"""

import json
import logging
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

# PersonalityLearningçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    # Phase 1ç”¨ã®åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
    from personality_learning_core_phase1 import MirralismPersonalityLearningPhase1 as MirralismPersonalityLearning
    PersonalityLearningDatabase = None  # Phase 1ã§ã¯ç°¡æ˜“å®Ÿè£…
except ImportError as e:
    logging.warning(f"PersonalityLearningçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    MirralismPersonalityLearning = None
    PersonalityLearningDatabase = None


class ClientDataProcessor:
    """MIRRALISM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³ (Phase 1)"""

    def __init__(self, project_root: Optional[Path] = None):
        """
        ClientDataProcessoråˆæœŸåŒ–
        
        Args:
            project_root: MIRRALISMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        """
        self.project_root = project_root or Path(__file__).parent.parent.parent
        self.setup_logging()
        
        # PersonalityLearningçµ±åˆåˆæœŸåŒ–
        self.personality_learning = None
        self.database = None
        
        if MirralismPersonalityLearning:
            try:
                self.personality_learning = MirralismPersonalityLearning()
                self.logger.info("âœ… PersonalityLearningçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº† (Phase 1)")
            except Exception as e:
                self.logger.error(f"âŒ PersonalityLearningåˆæœŸåŒ–å¤±æ•—: {e}")
        
        # çµ±è¨ˆæƒ…å ±
        self.processing_stats = {
            "clients_processed": 0,
            "integration_success": 0,
            "integration_failures": 0,
            "session_start": datetime.now(timezone.utc).isoformat()
        }

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - CLIENT_PROCESSOR - %(levelname)s - %(message)s"
        )
        self.logger = logging.getLogger(__name__)

    def load_client_profiles(self) -> Dict[str, Any]:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            client_db_path = self.project_root / "Clients" / "Database" / "client_profiles.json"
            
            with open(client_db_path, 'r', encoding='utf-8') as f:
                client_data = json.load(f)
            
            self.logger.info(f"âœ… ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {client_db_path}")
            return client_data
            
        except FileNotFoundError:
            self.logger.error(f"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {client_db_path}")
            return {}
        except Exception as e:
            self.logger.error(f"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def extract_client_personalities(self, client_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ã‹ã‚‰PersonalityLearningå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        extracted_data = []
        
        clients = client_data.get("clients", {})
        
        for client_name, client_info in clients.items():
            if client_name == "_template":  # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
                continue
                
            # åŸºæœ¬æƒ…å ±æŠ½å‡º
            personality_data = {
                "client_name": client_name,
                "formal_name": client_info.get("æ­£å¼åç§°", client_name),
                "industry": client_info.get("æ¥­ç•Œ", ""),
                "region": client_info.get("åœ°åŸŸ", ""),
                "representative": client_info.get("ä»£è¡¨è€…", ""),
                "business_overview": client_info.get("äº‹æ¥­æ¦‚è¦", ""),
                "management_philosophy": client_info.get("çµŒå–¶ç†å¿µ", ""),
                "management_policy": client_info.get("çµŒå–¶æ–¹é‡", ""),
                "current_challenges": client_info.get("ç¾åœ¨ã®èª²é¡Œ", []),
                "special_notes": client_info.get("ç‰¹è¨˜äº‹é …", []),
                "project_start_date": client_info.get("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹æ—¥", ""),
                "importance": client_info.get("é‡è¦åº¦", "medium"),
                "status": client_info.get("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "unknown")
            }
            
            # ä¸»è¦æ‹…å½“è€…æƒ…å ±æŠ½å‡º
            key_persons = client_info.get("ä¸»è¦æ‹…å½“è€…", [])
            personality_data["key_persons"] = []
            
            for person in key_persons:
                if isinstance(person, dict):
                    person_data = {
                        "name": person.get("åå‰", ""),
                        "position": person.get("å½¹è·", ""),
                        "characteristics": person.get("ç‰¹å¾´", ""),
                        "role_type": self._classify_role_type(person.get("å½¹è·", ""))
                    }
                    personality_data["key_persons"].append(person_data)
            
            # PersonalityLearningåˆ†æç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
            analysis_content = self._generate_analysis_content(personality_data)
            personality_data["analysis_content"] = analysis_content
            
            extracted_data.append(personality_data)
            
        self.logger.info(f"âœ… {len(extracted_data)}ä»¶ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º")
        return extracted_data

    def _classify_role_type(self, position: str) -> str:
        """å½¹è·ã‹ã‚‰ãƒ­ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡"""
        position_lower = position.lower()
        
        if any(word in position_lower for word in ["ä»£è¡¨", "ç¤¾é•·", "ceo", "president"]):
            return "decision_maker"
        elif any(word in position_lower for word in ["è£œä½", "é…å¶è€…", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼"]):
            return "key_supporter"
        elif any(word in position_lower for word in ["ç®¡ç†", "éƒ¨é•·", "manager", "director"]):
            return "middle_management"
        else:
            return "team_member"

    def _generate_analysis_content(self, client_data: Dict[str, Any]) -> str:
        """PersonalityLearningåˆ†æç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
        content_parts = []
        
        # åŸºæœ¬æƒ…å ±
        content_parts.append(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: {client_data['client_name']}")
        if client_data['business_overview']:
            content_parts.append(f"äº‹æ¥­æ¦‚è¦: {client_data['business_overview']}")
        
        # çµŒå–¶ç†å¿µãƒ»æ–¹é‡
        if client_data['management_philosophy']:
            content_parts.append(f"çµŒå–¶ç†å¿µ: {client_data['management_philosophy']}")
        if client_data['management_policy']:
            content_parts.append(f"çµŒå–¶æ–¹é‡: {client_data['management_policy']}")
        
        # ä¸»è¦æ‹…å½“è€…
        for person in client_data['key_persons']:
            if person['name'] and person['characteristics']:
                content_parts.append(f"{person['name']}({person['position']}): {person['characteristics']}")
        
        # èª²é¡Œãƒ»ç‰¹è¨˜äº‹é …
        if client_data['current_challenges']:
            challenges = client_data['current_challenges']
            if isinstance(challenges, list):
                content_parts.append(f"èª²é¡Œ: {', '.join(challenges)}")
            else:
                content_parts.append(f"èª²é¡Œ: {challenges}")
        
        return "\n".join(content_parts)

    def process_client_with_personality_learning(self, client_data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’PersonalityLearningåˆ†æ"""
        if not self.personality_learning:
            return {
                "success": False,
                "error": "PersonalityLearningçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“",
                "client_name": client_data.get("client_name", "unknown")
            }
        
        try:
            analysis_content = client_data["analysis_content"]
            client_name = client_data["client_name"]
            
            # PersonalityLearningåˆ†æå®Ÿè¡Œ
            analysis_result = self.personality_learning.analyze_entry(
                content=analysis_content,
                source_type="client_data",
                metadata={
                    "client_name": client_name,
                    "industry": client_data.get("industry", ""),
                    "importance": client_data.get("importance", "medium"),
                    "data_source": "client_profiles_database"
                }
            )
            
            if analysis_result.get("success", False):
                # çµ±è¨ˆæ›´æ–°
                self.processing_stats["integration_success"] += 1
                
                # çµ±åˆçµæœä½œæˆ
                integration_result = {
                    "success": True,
                    "client_name": client_name,
                    "analysis_result": analysis_result.get("analysis", {}),
                    "confidence": analysis_result.get("analysis", {}).get("suetake_likeness_index", 0.0),
                    "integration_metadata": {
                        "processed_at": datetime.now(timezone.utc).isoformat(),
                        "data_source": "client_profiles",
                        "processing_version": "phase1_concept"
                    }
                }
                
                self.logger.info(f"âœ… ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ†æå®Œäº†: {client_name} (ç²¾åº¦: {integration_result['confidence']}%)")
                return integration_result
            else:
                error_msg = analysis_result.get("error", "unknown")
                self.logger.warning(f"âš ï¸ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ†æå¤±æ•—: {client_name} - {error_msg}")
                self.processing_stats["integration_failures"] += 1
                return {
                    "success": False,
                    "error": error_msg,
                    "client_name": client_name
                }
                
        except Exception as e:
            self.logger.error(f"âŒ PersonalityLearningåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            self.processing_stats["integration_failures"] += 1
            return {
                "success": False,
                "error": str(e),
                "client_name": client_data.get("client_name", "unknown")
            }

    def save_integration_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """çµ±åˆçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        try:
            # çµ±åˆçµæœä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            results_dir = self.project_root / "Data" / "client_integration"
            results_dir.mkdir(parents=True, exist_ok=True)
            
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = results_dir / f"client_integration_results_{timestamp}.json"
            
            # ä¿å­˜ãƒ‡ãƒ¼ã‚¿æº–å‚™
            save_data = {
                "integration_metadata": {
                    "processing_date": datetime.now(timezone.utc).isoformat(),
                    "phase": "phase1_concept",
                    "processor_version": "v2.0_basic",
                    "total_clients": len(results),
                    "successful_integrations": len([r for r in results if r.get("success", False)]),
                    "failed_integrations": len([r for r in results if not r.get("success", False)])
                },
                "processing_stats": self.processing_stats,
                "integration_results": results
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"âœ… çµ±åˆçµæœä¿å­˜å®Œäº†: {results_file}")
            
            return {
                "success": True,
                "results_file": str(results_file),
                "total_processed": len(results),
                "successful": save_data["integration_metadata"]["successful_integrations"],
                "failed": save_data["integration_metadata"]["failed_integrations"]
            }
            
        except Exception as e:
            self.logger.error(f"âŒ çµ±åˆçµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def run_phase1_integration(self) -> Dict[str, Any]:
        """Phase 1 çµ±åˆå‡¦ç†å®Ÿè¡Œ"""
        self.logger.info("ğŸš€ MIRRALISM ClientDataProcessor Phase 1 çµ±åˆé–‹å§‹")
        
        try:
            # 1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            client_data = self.load_client_profiles()
            if not client_data:
                return {
                    "success": False,
                    "error": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ"
                }
            
            # 2. PersonalityLearningå¯¾è±¡ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            extracted_clients = self.extract_client_personalities(client_data)
            if not extracted_clients:
                return {
                    "success": False,
                    "error": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"
                }
            
            # 3. PersonalityLearningçµ±åˆåˆ†æ
            integration_results = []
            for client in extracted_clients:
                result = self.process_client_with_personality_learning(client)
                integration_results.append(result)
                self.processing_stats["clients_processed"] += 1
            
            # 4. çµæœä¿å­˜
            save_result = self.save_integration_results(integration_results)
            
            # 5. æœ€çµ‚çµæœç”Ÿæˆ
            final_result = {
                "success": True,
                "phase": "phase1_concept",
                "processing_summary": {
                    "total_clients": len(extracted_clients),
                    "successful_integrations": len([r for r in integration_results if r.get("success", False)]),
                    "failed_integrations": len([r for r in integration_results if not r.get("success", False)]),
                    "average_confidence": self._calculate_average_confidence(integration_results)
                },
                "integration_results": integration_results,
                "save_result": save_result,
                "processing_stats": self.processing_stats,
                "mirralism_compliance": {
                    "ssot_principle": True,
                    "quality_baseline": True,
                    "v1_lessons_applied": True
                }
            }
            
            self.logger.info("ğŸ¯ Phase 1 çµ±åˆå‡¦ç†å®Œäº†")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ Phase 1 çµ±åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_stats": self.processing_stats
            }

    def _calculate_average_confidence(self, results: List[Dict[str, Any]]) -> float:
        """å¹³å‡ä¿¡é ¼åº¦è¨ˆç®—"""
        successful_results = [r for r in results if r.get("success", False)]
        if not successful_results:
            return 0.0
        
        confidences = [r.get("confidence", 0.0) for r in successful_results]
        return sum(confidences) / len(confidences)

    def get_demo_data(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        return {
            "processor_status": "phase1_ready",
            "capabilities": [
                "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåŸºæœ¬æƒ…å ±çµ±åˆ",
                "PersonalityLearningåˆ†æ",
                "çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜",
                "åˆ†æçµæœå¯è¦–åŒ–"
            ],
            "integration_architecture": {
                "data_source": "Clients/Database/client_profiles.json",
                "processing_engine": "PersonalityLearning integrated_system",
                "output_destination": "Data/client_integration/",
                "analysis_accuracy": "åŸºæœ¬ãƒ¬ãƒ™ãƒ«ï¼ˆPhase 1ï¼‰"
            },
            "phase2_preview": {
                "enhanced_analysis": "æ·±å±¤å¿ƒç†åˆ†æ",
                "security_validation": "å®Œå…¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼",
                "performance_optimization": "é«˜é€Ÿå‡¦ç†æœ€é©åŒ–",
                "advanced_integrations": "WebDataçµ±åˆå¯¾å¿œ"
            },
            "mirralism_compliance": {
                "quality_standards": "ç¶­æŒæ¸ˆã¿",
                "v1_lessons": "é©ç”¨æ¸ˆã¿",
                "scalability": "è¨­è¨ˆæ¸ˆã¿"
            }
        }


# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
def run_phase1_demo():
    """Phase 1 ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    processor = ClientDataProcessor()
    result = processor.run_phase1_integration()
    
    print("ğŸ¯ MIRRALISM ClientDataProcessor Phase 1 ãƒ‡ãƒ¢")
    print("=" * 60)
    
    if result["success"]:
        summary = result["processing_summary"]
        print(f"âœ… çµ±åˆå‡¦ç†æˆåŠŸ")
        print(f"ğŸ“Š å‡¦ç†ã‚µãƒãƒªãƒ¼:")
        print(f"   ç·ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°: {summary['total_clients']}")
        print(f"   æˆåŠŸçµ±åˆ: {summary['successful_integrations']}")
        print(f"   å¤±æ•—çµ±åˆ: {summary['failed_integrations']}")
        print(f"   å¹³å‡ä¿¡é ¼åº¦: {summary['average_confidence']:.1f}%")
        
        # ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        demo_data = processor.get_demo_data()
        print(f"\nğŸ”§ çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:")
        arch = demo_data["integration_architecture"]
        for key, value in arch.items():
            print(f"   {key}: {value}")
    else:
        print(f"âŒ çµ±åˆå‡¦ç†å¤±æ•—: {result.get('error', 'unknown')}")
    
    return result


if __name__ == "__main__":
    run_phase1_demo()