#!/usr/bin/env python3
"""
MIRRALISM PersonalityLearning Core - Phase 1 æ¦‚å¿µå®Ÿè¨¼
===============================================

17æ™‚é–“å®Ÿè£…ã‚¹ã‚³ãƒ¼ãƒ—ã§ã®åŸºæœ¬PersonalityLearningæ©Ÿèƒ½
æ¦‚å¿µå®Ÿè¨¼ãƒ¬ãƒ™ãƒ«ã§ã®æœ€å°é™å®Ÿè£…

Phase 1 æ©Ÿèƒ½ç¯„å›²:
- åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
- ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ç”Ÿæˆ
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆæº–å‚™
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜æ©Ÿèƒ½

ä½œæˆè€…: MIRRALISM V2 æŠ€è¡“è€…
ä½œæˆæ—¥: 2025å¹´6æœˆ6æ—¥
"""

import json
import logging
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional


class PersonalityLearningCorePhase1:
    """PersonalityLearning Core Phase 1 å®Ÿè£…"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.setup_logging()
        self.analysis_stats = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "average_confidence": 0.0,
            "session_start": datetime.now(timezone.utc).isoformat()
        }
        
        # Phase 1 åŸºæœ¬åˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³
        self.analysis_patterns = {
            "positive_indicators": [
                "æˆåŠŸ", "å®Œäº†", "é”æˆ", "å‘ä¸Š", "æ”¹å–„", "æˆé•·", "ç™ºå±•", "é©æ–°",
                "åŠ¹ç‡", "å“è³ª", "ä¾¡å€¤", "æº€è¶³", "å¹¸ã›", "è²¢çŒ®", "å”åŠ›", "é€£æº"
            ],
            "leadership_indicators": [
                "ä»£è¡¨", "ç¤¾é•·", "ãƒªãƒ¼ãƒ€ãƒ¼", "æŒ‡å°", "æ–¹é‡", "ç†å¿µ", "çµŒå–¶", "æˆ¦ç•¥",
                "åˆ¤æ–­", "æ±ºå®š", "è²¬ä»»", "ç®¡ç†", "çµ±ç‡", "ãƒ“ã‚¸ãƒ§ãƒ³", "ç›®æ¨™"
            ],
            "relationship_indicators": [
                "å®¶æ—", "ç¤¾å“¡", "ãƒãƒ¼ãƒ ", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼", "å”æ¥­", "ä¿¡é ¼", "ç†è§£",
                "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³", "å¯¾è©±", "ç›¸è«‡", "æ”¯æ´", "ã‚µãƒãƒ¼ãƒˆ"
            ],
            "challenge_indicators": [
                "èª²é¡Œ", "å•é¡Œ", "å›°é›£", "æ”¹å–„", "å¯¾ç­–", "è§£æ±º", "å…‹æœ", "è¦‹ç›´ã—",
                "èª¿æ•´", "ä¿®æ­£", "å¼·åŒ–", "æœ€é©åŒ–", "åŠ¹ç‡åŒ–"
            ]
        }

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - PERSONALITY_CORE - %(levelname)s - %(message)s"
        )
        self.logger = logging.getLogger(__name__)

    def analyze_content(self, content: str, source_type: str = "text", metadata: Optional[Dict] = None) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æå®Ÿè¡Œ"""
        try:
            self.analysis_stats["total_analyses"] += 1
            
            # åŸºæœ¬åˆ†æå®Ÿè¡Œ
            analysis_result = self._perform_basic_analysis(content, source_type, metadata or {})
            
            # ä¿¡é ¼åº¦è¨ˆç®—
            confidence = self._calculate_confidence(analysis_result, content)
            
            # çµæœçµ±åˆ
            final_result = {
                "success": True,
                "analysis": {
                    "suetake_likeness_index": confidence,
                    "content_analysis": analysis_result,
                    "source_type": source_type,
                    "metadata": metadata or {},
                    "analysis_timestamp": datetime.now(timezone.utc).isoformat()
                },
                "processing_info": {
                    "phase": "phase1_concept",
                    "analysis_version": "v2.0_basic",
                    "content_length": len(content),
                    "pattern_matches": analysis_result.get("total_pattern_matches", 0)
                }
            }
            
            # çµ±è¨ˆæ›´æ–°
            self.analysis_stats["successful_analyses"] += 1
            self._update_confidence_average(confidence)
            
            self.logger.info(f"âœ… åˆ†æå®Œäº†: {source_type} (ä¿¡é ¼åº¦: {confidence:.1f}%)")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": {
                    "suetake_likeness_index": 0.0,
                    "source_type": source_type,
                    "metadata": metadata or {}
                }
            }

    def _perform_basic_analysis(self, content: str, source_type: str, metadata: Dict) -> Dict[str, Any]:
        """åŸºæœ¬åˆ†æå®Ÿè¡Œ"""
        content_lower = content.lower()
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°åˆ†æ
        pattern_scores = {}
        total_matches = 0
        
        for category, patterns in self.analysis_patterns.items():
            matches = 0
            for pattern in patterns:
                if pattern in content_lower:
                    matches += 1
                    total_matches += 1
            
            pattern_scores[category] = {
                "matches": matches,
                "total_patterns": len(patterns),
                "match_ratio": matches / len(patterns) if patterns else 0.0
            }
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç‰¹åŒ–åˆ†æï¼ˆsource_typeãŒclient_dataã®å ´åˆï¼‰
        client_specific_analysis = {}
        if source_type == "client_data":
            client_specific_analysis = self._analyze_client_specific_patterns(content, metadata)
        
        # åŸºæœ¬åˆ†æçµæœ
        analysis_result = {
            "pattern_analysis": pattern_scores,
            "total_pattern_matches": total_matches,
            "content_characteristics": {
                "length": len(content),
                "word_count": len(content.split()),
                "has_business_context": any(word in content_lower for word in ["äº‹æ¥­", "çµŒå–¶", "ä¼šç¤¾", "çµ„ç¹”"]),
                "has_relationship_context": any(word in content_lower for word in ["äºº", "ç¤¾å“¡", "å®¶æ—", "ãƒãƒ¼ãƒ "]),
                "has_improvement_context": any(word in content_lower for word in ["æ”¹å–„", "å‘ä¸Š", "æˆé•·", "ç™ºå±•"])
            },
            "client_specific": client_specific_analysis,
            "analysis_quality": self._assess_analysis_quality(content, total_matches)
        }
        
        return analysis_result

    def _analyze_client_specific_patterns(self, content: str, metadata: Dict) -> Dict[str, Any]:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç‰¹åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        content_lower = content.lower()
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥­ç•Œç‰¹åŒ–åˆ†æ
        industry = metadata.get("industry", "").lower()
        industry_relevance = 0.0
        
        if "å»ºè¨­" in industry or "ä½å®…" in industry:
            construction_terms = ["å»ºè¨­", "ä½å®…", "å»ºç¯‰", "å·¥å‹™åº—", "æ–½å·¥", "è¨­è¨ˆ"]
            matches = sum(1 for term in construction_terms if term in content_lower)
            industry_relevance = min(matches / len(construction_terms), 1.0)
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé‡è¦åº¦åˆ†æ
        importance = metadata.get("importance", "medium")
        importance_multiplier = {
            "high": 1.2,
            "medium": 1.0,
            "low": 0.8
        }.get(importance, 1.0)
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç‰¹åŒ–ã‚¹ã‚³ã‚¢
        client_focus_score = 0.0
        client_terms = ["ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ", "é¡§å®¢", "ãŠå®¢æ§˜", "å–å¼•å…ˆ", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼"]
        client_matches = sum(1 for term in client_terms if term in content_lower)
        client_focus_score = min(client_matches / len(client_terms), 1.0)
        
        return {
            "industry_relevance": industry_relevance,
            "importance_multiplier": importance_multiplier,
            "client_focus_score": client_focus_score,
            "business_context_strength": self._calculate_business_context_strength(content_lower)
        }

    def _calculate_business_context_strength(self, content_lower: str) -> float:
        """ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼·åº¦è¨ˆç®—"""
        business_terms = [
            "çµŒå–¶", "äº‹æ¥­", "ä¼šç¤¾", "çµ„ç¹”", "ç®¡ç†", "é‹å–¶", "æˆ¦ç•¥", "è¨ˆç”»",
            "ç›®æ¨™", "æˆæœ", "åŠ¹ç‡", "å“è³ª", "ä¾¡å€¤", "æˆé•·", "ç™ºå±•", "æ”¹å–„"
        ]
        
        matches = sum(1 for term in business_terms if term in content_lower)
        return min(matches / len(business_terms), 1.0)

    def _calculate_confidence(self, analysis_result: Dict[str, Any], content: str) -> float:
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        base_confidence = 60.0  # Phase 1 ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å¯„ä¸
        pattern_contribution = 0.0
        pattern_analysis = analysis_result.get("pattern_analysis", {})
        for category, data in pattern_analysis.items():
            match_ratio = data.get("match_ratio", 0.0)
            category_weight = {
                "positive_indicators": 8.0,
                "leadership_indicators": 10.0,
                "relationship_indicators": 7.0,
                "challenge_indicators": 5.0
            }.get(category, 5.0)
            pattern_contribution += match_ratio * category_weight
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªå¯„ä¸
        characteristics = analysis_result.get("content_characteristics", {})
        quality_bonus = 0.0
        
        if characteristics.get("has_business_context", False):
            quality_bonus += 5.0
        if characteristics.get("has_relationship_context", False):
            quality_bonus += 4.0
        if characteristics.get("has_improvement_context", False):
            quality_bonus += 3.0
        
        # é•·ã•ãƒœãƒ¼ãƒŠã‚¹
        content_length = len(content)
        length_bonus = min(content_length / 500 * 2.0, 5.0)  # æœ€å¤§5%ãƒœãƒ¼ãƒŠã‚¹
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç‰¹åŒ–ãƒœãƒ¼ãƒŠã‚¹
        client_specific = analysis_result.get("client_specific", {})
        client_bonus = 0.0
        if client_specific:
            client_bonus += client_specific.get("industry_relevance", 0.0) * 3.0
            client_bonus += client_specific.get("client_focus_score", 0.0) * 2.0
            client_bonus *= client_specific.get("importance_multiplier", 1.0)
        
        # æœ€çµ‚ä¿¡é ¼åº¦è¨ˆç®—
        final_confidence = base_confidence + pattern_contribution + quality_bonus + length_bonus + client_bonus
        
        # ä¸Šé™ãƒ»ä¸‹é™é©ç”¨
        return max(0.0, min(95.0, final_confidence))

    def _assess_analysis_quality(self, content: str, total_matches: int) -> str:
        """åˆ†æå“è³ªè©•ä¾¡"""
        content_length = len(content)
        match_density = total_matches / max(content_length / 100, 1)  # 100æ–‡å­—ã‚ãŸã‚Šã®ãƒãƒƒãƒæ•°
        
        if match_density >= 3.0 and content_length >= 200:
            return "high"
        elif match_density >= 1.5 and content_length >= 100:
            return "medium"
        else:
            return "basic"

    def _update_confidence_average(self, new_confidence: float):
        """å¹³å‡ä¿¡é ¼åº¦æ›´æ–°"""
        current_avg = self.analysis_stats["average_confidence"]
        total_analyses = self.analysis_stats["successful_analyses"]
        
        if total_analyses == 1:
            self.analysis_stats["average_confidence"] = new_confidence
        else:
            self.analysis_stats["average_confidence"] = (
                (current_avg * (total_analyses - 1) + new_confidence) / total_analyses
            )

    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±å–å¾—"""
        return self.analysis_stats.copy()

    def get_demo_analysis(self, content: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¢ç”¨åˆ†æå®Ÿè¡Œ"""
        return self.analyze_content(
            content=content,
            source_type="demo",
            metadata={"demo_mode": True, "phase": "phase1_concept"}
        )


# Phase 1 çµ±åˆã‚¯ãƒ©ã‚¹
class MirralismPersonalityLearningPhase1:
    """MIRRALISM PersonalityLearningçµ±åˆã‚·ã‚¹ãƒ†ãƒ  Phase 1"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.core = PersonalityLearningCorePhase1()
        self.setup_logging()

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        self.logger = logging.getLogger("MIRRALISM_PL_PHASE1")

    def analyze_entry(self, content: str, source_type: str = "text", metadata: Optional[Dict] = None, voice_data: Optional[Dict] = None) -> Dict[str, Any]:
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æï¼ˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ äº’æ›ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰"""
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            extended_metadata = metadata or {}
            if voice_data:
                extended_metadata["voice_data"] = voice_data
            
            # Coreåˆ†æå®Ÿè¡Œ
            result = self.core.analyze_content(content, source_type, extended_metadata)
            
            self.logger.info(f"âœ… çµ±åˆåˆ†æå®Œäº†: {source_type}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ çµ±åˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": {"suetake_likeness_index": 0.0}
            }

    def get_integration_status(self) -> Dict[str, Any]:
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—"""
        return {
            "phase": "phase1_concept",
            "core_available": True,
            "database_available": False,  # Phase 1ã§ã¯ç°¡æ˜“å®Ÿè£…
            "analysis_stats": self.core.get_stats(),
            "capabilities": [
                "åŸºæœ¬ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ",
                "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆ",
                "ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ç”Ÿæˆ",
                "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°åˆ†æ"
            ],
            "limitations": [
                "Phase 1 æ¦‚å¿µå®Ÿè¨¼ãƒ¬ãƒ™ãƒ«",
                "åŸºæœ¬åˆ†ææ©Ÿèƒ½ã®ã¿",
                "å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã¯ Phase 2"
            ]
        }


if __name__ == "__main__":
    # Phase 1 ãƒ‡ãƒ¢å®Ÿè¡Œ
    pl_system = MirralismPersonalityLearningPhase1()
    
    test_content = """
    é»’æ¾¤å·¥å‹™åº—æ ªå¼ä¼šç¤¾ã¯ã€ã•ã„ãŸã¾å¸‚ã®å»ºè¨­æ¥­ãƒ»ä½å®…å»ºç¯‰ä¼šç¤¾ã§ã™ã€‚
    ä»£è¡¨è€…ã®é»’æ¾¤ç¤¾é•·ã¯ç†å¿µé‡è¦–å‹ã®ãƒªãƒ¼ãƒ€ãƒ¼ã§ã€ã€Œç¤¾å“¡ã¨å®¶æ—ã€ä¼šç¤¾ã‚’å–ã‚Šå·»ãå…¨ã¦ã®äººã€…ã‚’å¹¸ã›ã«ã™ã‚‹ã€
    ã¨ã„ã†çµŒå–¶ç†å¿µã‚’æ²ã’ã¦ã„ã¾ã™ã€‚ç¾åœ¨ã®èª²é¡Œã¨ã—ã¦çµ„ç¹”å†…ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½“åˆ¶ã®æ”¹å–„ã‚„
    äººæä¸è¶³ã¨æ¥­å‹™åŠ¹ç‡ã®å‘ä¸ŠãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
    """
    
    result = pl_system.analyze_entry(
        content=test_content,
        source_type="client_data",
        metadata={
            "client_name": "é»’æ¾¤å·¥å‹™åº—",
            "industry": "å»ºè¨­æ¥­ãƒ»ä½å®…å»ºç¯‰",
            "importance": "high"
        }
    )
    
    print("ğŸ¯ MIRRALISM PersonalityLearning Phase 1 ãƒ‡ãƒ¢")
    print("=" * 50)
    
    if result["success"]:
        analysis = result["analysis"]
        print(f"âœ… åˆ†ææˆåŠŸ")
        print(f"ğŸ“Š ä¿¡é ¼åº¦: {analysis['suetake_likeness_index']:.1f}%")
        print(f"ğŸ” åˆ†æå“è³ª: {analysis['content_analysis']['analysis_quality']}")
        print(f"ğŸ“ˆ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæ•°: {analysis['content_analysis']['total_pattern_matches']}")
    else:
        print(f"âŒ åˆ†æå¤±æ•—: {result.get('error', 'unknown')}")
    
    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
    status = pl_system.get_integration_status()
    print(f"\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: Phase {status['phase']}")
    print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½æ©Ÿèƒ½: {len(status['capabilities'])}å€‹")