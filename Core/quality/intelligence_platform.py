#!/usr/bin/env python3
"""
MIRRALISM Quality Intelligence Platform
Purpose: Predictive quality assurance with self-healing capabilities
Design: AI-powered quality intelligence beyond simple monitoring

Created: 2025-06-07
Version: 1.0.0
"""

import json
import time
import asyncio
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum
import sqlite3
import hashlib
import statistics
from collections import defaultdict, deque


class QualityLevel(Enum):
    """å“è³ªãƒ¬ãƒ™ãƒ«å®šç¾©"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class AlertType(Enum):
    """ã‚¢ãƒ©ãƒ¼ãƒˆç¨®åˆ¥"""
    PREDICTION = "prediction"
    ANOMALY = "anomaly"
    FAILURE = "failure"
    RECOVERY = "recovery"
    OPTIMIZATION = "optimization"


@dataclass
class QualityMetric:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: datetime
    metric_name: str
    value: float
    unit: str
    category: str
    source: str
    metadata: Dict[str, Any] = None


@dataclass
class QualityAlert:
    """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆ"""
    alert_id: str
    timestamp: datetime
    alert_type: AlertType
    level: QualityLevel
    title: str
    description: str
    affected_components: List[str]
    predicted_impact: str
    recommended_actions: List[str]
    auto_resolution_available: bool = False
    metadata: Dict[str, Any] = None


@dataclass
class QualityPattern:
    """å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
    pattern_id: str
    pattern_type: str
    conditions: Dict[str, Any]
    outcomes: List[str]
    confidence_score: float
    occurrence_count: int
    last_seen: datetime


class QualityIntelligencePlatform:
    """MIRRALISMå“è³ªã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ """
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.data_dir = self.project_root / "Data" / "quality_intelligence"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.db_path = self.data_dir / "quality_intelligence.db"
        self._init_database()
        
        # ãƒ­ã‚°è¨­å®š
        self.log_path = self.data_dir / "intelligence.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_path),
                logging.StreamHandler()
            ]
        )
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ï¼ˆãƒ¡ãƒ¢ãƒªå†…ï¼‰
        self.metrics_history = deque(maxlen=10000)
        self.alert_history = deque(maxlen=1000)
        self.pattern_cache = {}
        
        # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹
        self.prediction_models = {}
        self.anomaly_detectors = {}
        
        logging.info("ğŸš€ MIRRALISM Quality Intelligence Platform initialized")
        
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    metric_name TEXT NOT NULL,
                    value REAL NOT NULL,
                    unit TEXT,
                    category TEXT,
                    source TEXT,
                    metadata TEXT
                )
            """)
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    alert_id TEXT UNIQUE NOT NULL,
                    timestamp TEXT NOT NULL,
                    alert_type TEXT NOT NULL,
                    level TEXT NOT NULL,
                    title TEXT NOT NULL,
                    description TEXT,
                    affected_components TEXT,
                    predicted_impact TEXT,
                    recommended_actions TEXT,
                    auto_resolution_available BOOLEAN,
                    metadata TEXT,
                    resolved BOOLEAN DEFAULT FALSE,
                    resolved_at TEXT,
                    resolution_method TEXT
                )
            """)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pattern_id TEXT UNIQUE NOT NULL,
                    pattern_type TEXT NOT NULL,
                    conditions TEXT NOT NULL,
                    outcomes TEXT NOT NULL,
                    confidence_score REAL NOT NULL,
                    occurrence_count INTEGER NOT NULL,
                    last_seen TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            """)
            
            conn.commit()
            
    def collect_metric(self, metric: QualityMetric):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        # ãƒ¡ãƒ¢ãƒªå±¥æ­´ã«è¿½åŠ 
        self.metrics_history.append(metric)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO metrics 
                (timestamp, metric_name, value, unit, category, source, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                metric.timestamp.isoformat(),
                metric.metric_name,
                metric.value,
                metric.unit,
                metric.category,
                metric.source,
                json.dumps(metric.metadata) if metric.metadata else None
            ))
            conn.commit()
            
        # ç•°å¸¸æ¤œå‡ºå®Ÿè¡Œ
        self._detect_anomalies(metric)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        self._learn_patterns(metric)
        
    def _detect_anomalies(self, metric: QualityMetric):
        """ç•°å¸¸æ¤œå‡º"""
        metric_name = metric.metric_name
        
        # éå»ãƒ‡ãƒ¼ã‚¿å–å¾—
        recent_values = [
            m.value for m in self.metrics_history 
            if m.metric_name == metric_name and 
            (datetime.now() - m.timestamp).days <= 7
        ]
        
        if len(recent_values) < 10:
            return  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³
            
        # çµ±è¨ˆçš„ç•°å¸¸æ¤œå‡º
        mean_val = statistics.mean(recent_values)
        stdev_val = statistics.stdev(recent_values) if len(recent_values) > 1 else 0
        
        if stdev_val > 0:
            z_score = abs(metric.value - mean_val) / stdev_val
            
            if z_score > 3:  # 3Ïƒã‚’è¶…ãˆã‚‹ç•°å¸¸
                alert = self._create_anomaly_alert(metric, z_score, mean_val)
                self.emit_alert(alert)
                
    def _learn_patterns(self, metric: QualityMetric):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        # æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
        self._learn_temporal_patterns(metric)
        
        # ç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’
        self._learn_correlation_patterns(metric)
        
    def _learn_temporal_patterns(self, metric: QualityMetric):
        """æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        metric_name = metric.metric_name
        
        # éå»1æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        recent_metrics = [
            m for m in self.metrics_history
            if m.metric_name == metric_name and
            (datetime.now() - m.timestamp).seconds <= 3600
        ]
        
        if len(recent_metrics) >= 5:
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            values = [m.value for m in recent_metrics]
            trend = self._calculate_trend(values)
            
            if abs(trend) > 0.1:  # æœ‰æ„ãªãƒˆãƒ¬ãƒ³ãƒ‰
                pattern_id = f"trend_{metric_name}_{int(time.time())}"
                pattern = QualityPattern(
                    pattern_id=pattern_id,
                    pattern_type="temporal_trend",
                    conditions={"metric": metric_name, "trend": trend},
                    outcomes=["trend_detected"],
                    confidence_score=min(abs(trend), 1.0),
                    occurrence_count=1,
                    last_seen=datetime.now()
                )
                self._save_pattern(pattern)
                
    def _learn_correlation_patterns(self, metric: QualityMetric):
        """ç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        # åŒæ™‚æœŸã®ä»–ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã®ç›¸é–¢ã‚’å­¦ç¿’
        current_time = metric.timestamp
        time_window = timedelta(minutes=5)
        
        concurrent_metrics = [
            m for m in self.metrics_history
            if abs((m.timestamp - current_time).total_seconds()) <= time_window.total_seconds()
            and m.metric_name != metric.metric_name
        ]
        
        for other_metric in concurrent_metrics:
            correlation_strength = self._calculate_correlation(
                metric.metric_name, other_metric.metric_name
            )
            
            if correlation_strength > 0.7:  # å¼·ã„ç›¸é–¢
                pattern_id = f"corr_{metric.metric_name}_{other_metric.metric_name}"
                pattern = QualityPattern(
                    pattern_id=pattern_id,
                    pattern_type="correlation",
                    conditions={
                        "primary_metric": metric.metric_name,
                        "correlated_metric": other_metric.metric_name,
                        "correlation": correlation_strength
                    },
                    outcomes=["correlation_detected"],
                    confidence_score=correlation_strength,
                    occurrence_count=1,
                    last_seen=datetime.now()
                )
                self._save_pattern(pattern)
                
    def predict_quality_issues(self) -> List[QualityAlert]:
        """å“è³ªå•é¡Œã®äºˆæ¸¬"""
        predictions = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹äºˆæ¸¬
        patterns = self._load_recent_patterns()
        for pattern in patterns:
            if pattern.confidence_score > 0.8:
                prediction = self._generate_prediction_from_pattern(pattern)
                if prediction:
                    predictions.append(prediction)
                    
        # æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹äºˆæ¸¬ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
        # predictions.extend(self._ml_based_predictions())
        
        return predictions
        
    def _generate_prediction_from_pattern(self, pattern: QualityPattern) -> Optional[QualityAlert]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®äºˆæ¸¬ç”Ÿæˆ"""
        if pattern.pattern_type == "temporal_trend":
            # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ™ãƒ¼ã‚¹äºˆæ¸¬
            conditions = pattern.conditions
            trend = conditions.get("trend", 0)
            
            if abs(trend) > 0.2:  # æ€¥æ¿€ãªå¤‰åŒ–
                alert_id = f"pred_{pattern.pattern_id}_{int(time.time())}"
                return QualityAlert(
                    alert_id=alert_id,
                    timestamp=datetime.now(),
                    alert_type=AlertType.PREDICTION,
                    level=QualityLevel.MEDIUM,
                    title=f"Quality degradation predicted for {conditions['metric']}",
                    description=f"Trend analysis indicates potential quality issues (trend: {trend:.3f})",
                    affected_components=[conditions['metric']],
                    predicted_impact="Performance degradation expected within 30 minutes",
                    recommended_actions=[
                        "Monitor metric closely",
                        "Prepare contingency plans",
                        "Consider preemptive scaling"
                    ],
                    auto_resolution_available=False
                )
                
        return None
        
    def emit_alert(self, alert: QualityAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç™ºä¿¡"""
        self.alert_history.append(alert)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT OR REPLACE INTO alerts 
                (alert_id, timestamp, alert_type, level, title, description, 
                 affected_components, predicted_impact, recommended_actions, 
                 auto_resolution_available, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                alert.alert_id,
                alert.timestamp.isoformat(),
                alert.alert_type.value,
                alert.level.value,
                alert.title,
                alert.description,
                json.dumps(alert.affected_components),
                alert.predicted_impact,
                json.dumps(alert.recommended_actions),
                alert.auto_resolution_available,
                json.dumps(alert.metadata) if alert.metadata else None
            ))
            conn.commit()
            
        # ãƒ­ã‚°å‡ºåŠ›
        level_icons = {
            QualityLevel.CRITICAL: "ğŸš¨",
            QualityLevel.HIGH: "âš ï¸",
            QualityLevel.MEDIUM: "ğŸ”¶",
            QualityLevel.LOW: "ğŸ”¸",
            QualityLevel.INFO: "â„¹ï¸"
        }
        
        icon = level_icons.get(alert.level, "ğŸ“Š")
        logging.warning(f"{icon} ALERT: {alert.title}")
        logging.info(f"   Description: {alert.description}")
        logging.info(f"   Components: {', '.join(alert.affected_components)}")
        
        # è‡ªå‹•ä¿®å¾©è©¦è¡Œ
        if alert.auto_resolution_available:
            self.attempt_auto_resolution(alert)
            
    def attempt_auto_resolution(self, alert: QualityAlert) -> bool:
        """è‡ªå‹•ä¿®å¾©è©¦è¡Œ"""
        resolution_strategies = {
            "mcp_connection_issue": self._resolve_mcp_connection,
            "high_memory_usage": self._resolve_memory_issue,
            "slow_response_time": self._resolve_performance_issue
        }
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«åŸºã¥ãä¿®å¾©æˆ¦ç•¥é¸æŠ
        for strategy_key, strategy_func in resolution_strategies.items():
            if strategy_key in alert.description.lower():
                success = strategy_func(alert)
                if success:
                    self._mark_alert_resolved(alert, f"auto_resolution_{strategy_key}")
                    return True
                    
        return False
        
    def generate_quality_report(self) -> Dict[str, Any]:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        now = datetime.now()
        
        # éå»24æ™‚é–“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        recent_metrics = [
            m for m in self.metrics_history
            if (now - m.timestamp).days == 0
        ]
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category_stats = defaultdict(list)
        for metric in recent_metrics:
            category_stats[metric.category].append(metric.value)
            
        # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
        recent_alerts = [
            a for a in self.alert_history
            if (now - a.timestamp).days == 0
        ]
        
        alert_by_level = defaultdict(int)
        for alert in recent_alerts:
            alert_by_level[alert.level.value] += 1
            
        return {
            "report_timestamp": now.isoformat(),
            "period": "24h",
            "metrics_collected": len(recent_metrics),
            "category_statistics": {
                cat: {
                    "count": len(values),
                    "average": statistics.mean(values) if values else 0,
                    "min": min(values) if values else 0,
                    "max": max(values) if values else 0
                }
                for cat, values in category_stats.items()
            },
            "alerts_generated": len(recent_alerts),
            "alerts_by_level": dict(alert_by_level),
            "quality_score": self._calculate_overall_quality_score(),
            "recommendations": self._generate_recommendations()
        }
        
    def _calculate_overall_quality_score(self) -> float:
        """ç·åˆå“è³ªã‚¹ã‚³ã‚¢ç®—å‡º"""
        # ç°¡æ˜“ç‰ˆï¼šã‚¢ãƒ©ãƒ¼ãƒˆæ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®‰å®šæ€§ã‹ã‚‰ç®—å‡º
        recent_alerts = [
            a for a in self.alert_history
            if (datetime.now() - a.timestamp).days == 0
        ]
        
        alert_penalty = len(recent_alerts) * 10
        base_score = 100
        
        return max(0, min(100, base_score - alert_penalty))
        
    def _generate_recommendations(self) -> List[str]:
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã«ã‚ˆã‚‹æ¨å¥¨
        patterns = self._load_recent_patterns()
        high_confidence_patterns = [p for p in patterns if p.confidence_score > 0.8]
        
        if high_confidence_patterns:
            recommendations.append("Review recurring quality patterns for optimization opportunities")
            
        # ã‚¢ãƒ©ãƒ¼ãƒˆé »åº¦ã«ã‚ˆã‚‹æ¨å¥¨
        recent_alerts = [
            a for a in self.alert_history
            if (datetime.now() - a.timestamp).days <= 7
        ]
        
        if len(recent_alerts) > 10:
            recommendations.append("Consider implementing additional preventive measures")
            
        return recommendations
        
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    def _calculate_trend(self, values: List[float]) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        if len(values) < 2:
            return 0
        return (values[-1] - values[0]) / len(values)
        
    def _calculate_correlation(self, metric1: str, metric2: str) -> float:
        """ç›¸é–¢è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # å®Ÿè£…ã®ç°¡ç•¥åŒ–ï¼šå®Ÿéš›ã¯çµ±è¨ˆçš„ç›¸é–¢è¨ˆç®—ã‚’å®Ÿè£…
        return 0.5  # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        
    def _save_pattern(self, pattern: QualityPattern):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT OR REPLACE INTO patterns
                (pattern_id, pattern_type, conditions, outcomes, confidence_score,
                 occurrence_count, last_seen, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                pattern.pattern_id,
                pattern.pattern_type,
                json.dumps(pattern.conditions),
                json.dumps(pattern.outcomes),
                pattern.confidence_score,
                pattern.occurrence_count,
                pattern.last_seen.isoformat(),
                datetime.now().isoformat()
            ))
            conn.commit()
            
    def _load_recent_patterns(self) -> List[QualityPattern]:
        """æœ€è¿‘ã®ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT pattern_id, pattern_type, conditions, outcomes, 
                       confidence_score, occurrence_count, last_seen
                FROM patterns
                WHERE datetime(last_seen) > datetime('now', '-7 days')
                ORDER BY confidence_score DESC
            """)
            
            patterns = []
            for row in cursor.fetchall():
                patterns.append(QualityPattern(
                    pattern_id=row[0],
                    pattern_type=row[1],
                    conditions=json.loads(row[2]),
                    outcomes=json.loads(row[3]),
                    confidence_score=row[4],
                    occurrence_count=row[5],
                    last_seen=datetime.fromisoformat(row[6])
                ))
                
            return patterns
            
    def _create_anomaly_alert(self, metric: QualityMetric, z_score: float, mean_val: float) -> QualityAlert:
        """ç•°å¸¸ã‚¢ãƒ©ãƒ¼ãƒˆä½œæˆ"""
        alert_id = f"anomaly_{metric.metric_name}_{int(time.time())}"
        
        level = QualityLevel.HIGH if z_score > 5 else QualityLevel.MEDIUM
        
        return QualityAlert(
            alert_id=alert_id,
            timestamp=datetime.now(),
            alert_type=AlertType.ANOMALY,
            level=level,
            title=f"Anomaly detected in {metric.metric_name}",
            description=f"Value {metric.value} deviates significantly from mean {mean_val:.2f} (z-score: {z_score:.2f})",
            affected_components=[metric.source],
            predicted_impact="Potential system degradation",
            recommended_actions=[
                "Investigate root cause",
                "Monitor related metrics",
                "Consider scaling or optimization"
            ],
            auto_resolution_available=False
        )
        
    def _resolve_mcp_connection(self, alert: QualityAlert) -> bool:
        """MCPæ¥ç¶šå•é¡Œè§£æ±º"""
        # å®Ÿè£…ä¾‹ï¼šMCPå†èµ·å‹•è©¦è¡Œ
        logging.info("ğŸ”§ Attempting MCP connection recovery...")
        # å®Ÿéš›ã®ä¿®å¾©ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        return True
        
    def _resolve_memory_issue(self, alert: QualityAlert) -> bool:
        """ãƒ¡ãƒ¢ãƒªå•é¡Œè§£æ±º"""
        logging.info("ğŸ”§ Attempting memory optimization...")
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¼·åˆ¶å®Ÿè¡Œãªã©
        return True
        
    def _resolve_performance_issue(self, alert: QualityAlert) -> bool:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œè§£æ±º"""
        logging.info("ğŸ”§ Attempting performance optimization...")
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã€ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–ãªã©
        return True
        
    def _mark_alert_resolved(self, alert: QualityAlert, resolution_method: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±ºãƒãƒ¼ã‚¯"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE alerts 
                SET resolved = TRUE, resolved_at = ?, resolution_method = ?
                WHERE alert_id = ?
            """, (datetime.now().isoformat(), resolution_method, alert.alert_id))
            conn.commit()
            
        logging.info(f"âœ… Alert {alert.alert_id} resolved via {resolution_method}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼ˆãƒ‡ãƒ¢ï¼‰"""
    platform = QualityIntelligencePlatform()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    sample_metrics = [
        QualityMetric(
            timestamp=datetime.now(),
            metric_name="response_time",
            value=0.5,
            unit="seconds",
            category="performance",
            source="api_server"
        ),
        QualityMetric(
            timestamp=datetime.now(),
            metric_name="memory_usage",
            value=75.0,
            unit="percent",
            category="system",
            source="main_process"
        ),
        QualityMetric(
            timestamp=datetime.now(),
            metric_name="error_rate",
            value=0.01,
            unit="percent",
            category="reliability",
            source="application"
        )
    ]
    
    for metric in sample_metrics:
        platform.collect_metric(metric)
        
    # äºˆæ¸¬å®Ÿè¡Œ
    predictions = platform.predict_quality_issues()
    for prediction in predictions:
        platform.emit_alert(prediction)
        
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = platform.generate_quality_report()
    print(json.dumps(report, indent=2))


if __name__ == "__main__":
    asyncio.run(main())