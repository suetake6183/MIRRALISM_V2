#!/usr/bin/env python3
"""
SuperWhisper-Notionçµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ™‚åˆ»ãƒã‚°ä¿®æ­£çµ±åˆç‰ˆï¼‰
ä½œæˆè€…: æŠ€è¡“è€…
ä½œæˆæ—¥: 2025å¹´5æœˆ30æ—¥
ä¿®æ­£æ—¥: 2025å¹´6æœˆ3æ—¥ï¼ˆæ™‚åˆ»ãƒã‚°ä¿®æ­£çµ±åˆï¼‰
ç›®çš„: SuperWhisperéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®Notionå–å¾—ã¨ã‚¤ãƒ³ãƒœãƒƒã‚¯ã‚¹é…ç½®è‡ªå‹•åŒ–

CTOæˆ¦ç•¥æŒ‡ç¤º:
- Notionâ†’ã‚¤ãƒ³ãƒœãƒƒã‚¯ã‚¹é…ç½®æˆ¦ç•¥ã®å®Ÿè£…
- ğŸ’­ Personal_Thoughts/ å„ªå…ˆé…ç½®
- ğŸ“¥ Inbox_Raw/ è£œå®Œé…ç½®
- PersonalityLearningçµ±åˆæº–å‚™

ğŸ”§ é‡è¦ãªä¿®æ­£ï¼ˆv2.1ï¼‰:
- æ—¥æœ¬èªç’°å¢ƒã§ã®æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå•é¡Œã‚’æ ¹æœ¬è§£æ±º
- ISO 8601å®Œå…¨å½¢å¼ã®å¼·åˆ¶å®Ÿè£…
- ä¸å®Œå…¨ãªæ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ä¿®æ­£æ©Ÿèƒ½
- 00:00:00å¢ƒç•Œæ™‚åˆ»ã§ã®å‡¦ç†æ”¹å–„
"""

import json
import logging
import re
import sqlite3
import sys
import time
from datetime import datetime
from datetime import timedelta
from datetime import timezone
from pathlib import Path
from typing import Any
from typing import Dict
from typing import List
from typing import Optional

import requests

# ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ã‚¹è¿½åŠ 
current_dir = Path(__file__).parent
sys.path.append(str(current_dir.parent.parent / "AI_Systems" / "Core"))


class SuperWhisperNotionIntegration:
    """SuperWhisper-Notionçµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ™‚åˆ»ãƒã‚°ä¿®æ­£ç‰ˆï¼‰"""

    def __init__(self, config_path: str = None):
        """
        ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.base_dir = Path(__file__).parent.parent.parent  # SecondBrain/
        self.inbox_dir = self.base_dir / "00_Inbox"
        self.personal_thoughts_dir = self.inbox_dir / "ğŸ’­ Personal_Thoughts"
        self.inbox_raw_dir = self.inbox_dir / "ğŸ“¥ Inbox_Raw"

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèªãƒ»ä½œæˆ
        self.personal_thoughts_dir.mkdir(parents=True, exist_ok=True)
        self.inbox_raw_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ­ã‚°è¨­å®š
        self.logger = self._setup_logger()

        # è¨­å®šèª­ã¿è¾¼ã¿
        self.config = self._load_config(config_path)

        # Notion APIè¨­å®š
        self.notion_token = self.config.get("notion_token")
        self.notion_database_id = self.config.get("notion_database_id")

        # å‡¦ç†æ¸ˆã¿ã‚¨ãƒ³ãƒˆãƒªç®¡ç†ç”¨DB
        self.processed_db = (
            self.base_dir / ".system_internal" / "superwhisper_processed.db"
        )
        self.processed_db.parent.mkdir(parents=True, exist_ok=True)
        self._init_processed_db()

        self.logger.info("SuperWhisper-Notionçµ±åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ™‚åˆ»ä¿®æ­£ç‰ˆï¼‰åˆæœŸåŒ–å®Œäº†")

    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger("SuperWhisperNotionIntegration")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            log_dir = self.base_dir / ".system_internal" / "_LOGS"
            log_dir.mkdir(parents=True, exist_ok=True)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            log_file = log_dir / "superwhisper_integration.log"
            file_handler = logging.FileHandler(log_file, encoding="utf-8")
            file_formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)

            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            console_handler = logging.StreamHandler()
            console_formatter = logging.Formatter(
                "%(asctime)s - %(levelname)s - %(message)s"
            )
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)

        return logger

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        if config_path is None:
            config_path = (
                self.base_dir
                / "30_Resources"
                / "Configuration"
                / "superwhisper_config.json"
            )

        try:
            if Path(config_path).exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šä½œæˆ
                default_config = {
                    "notion_token": "YOUR_NOTION_TOKEN_HERE",
                    "notion_database_id": "YOUR_DATABASE_ID_HERE",
                    "monitor_interval": 300,  # 5åˆ†é–“éš”
                    "quality_threshold": 0.9,  # è»¢å†™å“è³ªé–¾å€¤
                    "min_text_length": 20,  # æœ€å°æ–‡å­—æ•°
                    "max_noise_level": 0.3,  # æœ€å¤§ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«
                }

                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                config_path.parent.mkdir(parents=True, exist_ok=True)
                with open(config_path, "w", encoding="utf-8") as f:
                    json.dump(default_config, f, indent=2, ensure_ascii=False)

                self.logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {config_path}")
                self.logger.warning("Notion APIè¨­å®šã‚’ç·¨é›†ã—ã¦ãã ã•ã„")

                return default_config

        except Exception as e:
            self.logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _init_processed_db(self):
        """å‡¦ç†æ¸ˆã¿ã‚¨ãƒ³ãƒˆãƒªç®¡ç†DBåˆæœŸåŒ–"""
        try:
            conn = sqlite3.connect(str(self.processed_db))
            cursor = conn.cursor()

            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS processed_entries (
                    notion_id TEXT PRIMARY KEY,
                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    file_path TEXT,
                    classification TEXT,
                    quality_score REAL
                )
            """
            )

            conn.commit()
            conn.close()

        except Exception as e:
            self.logger.error(f"å‡¦ç†æ¸ˆã¿DBåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def _fix_datetime_format(self, raw_datetime: str) -> str:
        """
        ğŸ”§ æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¿®æ­£ï¼ˆãƒã‚°ä¿®æ­£ã®æ ¸å¿ƒï¼‰

        æ—¥æœ¬èªç’°å¢ƒã§ç™ºç”Ÿã™ã‚‹ä¸å®Œå…¨ãªæ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’
        ISO 8601å®Œå…¨å½¢å¼ã«ä¿®æ­£ã™ã‚‹

        Args:
            raw_datetime: Notionã‹ã‚‰å—ã‘å–ã£ãŸç”Ÿã®æ™‚åˆ»æ–‡å­—åˆ—

        Returns:
            ISO 8601æº–æ‹ ã®å®Œå…¨ãªæ™‚åˆ»æ–‡å­—åˆ—
        """
        if not raw_datetime:
            # ç©ºã®å ´åˆã¯ç¾åœ¨æ™‚åˆ»ã‚’ä½¿ç”¨
            now = datetime.now(timezone.utc)
            fixed_time = now.isoformat()
            self.logger.warning(f"ç©ºã®æ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£: {fixed_time}")
            return fixed_time

        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: å®Œå…¨ãªISOå½¢å¼ (æ­£å¸¸ã‚±ãƒ¼ã‚¹)
            if re.match(r"\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}", raw_datetime):
                dt = datetime.fromisoformat(raw_datetime.replace("Z", "+00:00"))
                return dt.isoformat()

            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ—¥ä»˜ã®ã¿ï¼ˆãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            if re.match(r"^\d{4}-\d{2}-\d{2}$", raw_datetime):
                # æ—¥ä»˜ã®ã¿ã®å ´åˆã€00:00:00 UTCã¨ã—ã¦è£œå®Œ
                dt = datetime.fromisoformat(f"{raw_datetime}T00:00:00+00:00")
                fixed_time = dt.isoformat()
                self.logger.warning(f"ä¸å®Œå…¨ãªæ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£: {raw_datetime} â†’ {fixed_time}")
                return fixed_time

            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: æ™‚åˆ»ã¯ã‚ã‚‹ãŒã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãªã—
            if re.match(r"^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}$", raw_datetime):
                dt = datetime.fromisoformat(f"{raw_datetime}+00:00")
                fixed_time = dt.isoformat()
                self.logger.info(f"ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’è£œå®Œ: {raw_datetime} â†’ {fixed_time}")
                return fixed_time

            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: ãã®ä»–ã®å½¢å¼ã‚’å¼·åˆ¶ãƒ‘ãƒ¼ã‚¹
            try:
                # å¯èƒ½ãªé™ã‚Šãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                dt = datetime.fromisoformat(raw_datetime.replace("Z", "+00:00"))
                return dt.isoformat()
            except:
                # å®Œå…¨ã«å¤±æ•—ã—ãŸå ´åˆã¯ç¾åœ¨æ™‚åˆ»ã§ä»£æ›¿
                now = datetime.now(timezone.utc)
                fixed_time = now.isoformat()
                self.logger.error(f"æ™‚åˆ»ãƒ‘ãƒ¼ã‚¹å¤±æ•—ã€ç¾åœ¨æ™‚åˆ»ã§ä»£æ›¿: {raw_datetime} â†’ {fixed_time}")
                return fixed_time

        except Exception as e:
            # ä¾‹å¤–ç™ºç”Ÿæ™‚ã¯ç¾åœ¨æ™‚åˆ»ã§ä»£æ›¿
            now = datetime.now(timezone.utc)
            fixed_time = now.isoformat()
            self.logger.error(f"æ™‚åˆ»ä¿®æ­£å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({raw_datetime}): {e} â†’ {fixed_time}")
            return fixed_time

    def _validate_datetime_quality(self, original: str, fixed: str) -> Dict[str, Any]:
        """
        æ™‚åˆ»ä¿®æ­£ã®å“è³ªæ¤œè¨¼

        Args:
            original: å…ƒã®æ™‚åˆ»æ–‡å­—åˆ—
            fixed: ä¿®æ­£å¾Œã®æ™‚åˆ»æ–‡å­—åˆ—

        Returns:
            æ¤œè¨¼çµæœ
        """
        result = {
            "is_fixed": original != fixed,
            "original": original,
            "fixed": fixed,
            "fix_type": "none",
        }

        if not original:
            result["fix_type"] = "empty_to_current"
        elif re.match(r"^\d{4}-\d{2}-\d{2}$", original):
            result["fix_type"] = "date_only_to_full"
        elif original != fixed:
            result["fix_type"] = "timezone_completion"

        return result

    def fetch_notion_entries(self, hours_back: int = 24) -> List[Dict[str, Any]]:
        """
        Notionã‹ã‚‰æ–°è¦ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—

        Args:
            hours_back: ä½•æ™‚é–“å‰ã¾ã§é¡ã‚‹ã‹

        Returns:
            æ–°è¦ã‚¨ãƒ³ãƒˆãƒªãƒªã‚¹ãƒˆ
        """
        if not self.notion_token or not self.notion_database_id:
            self.logger.error("Notion APIè¨­å®šãŒä¸å®Œå…¨ã§ã™")
            return []

        try:
            headers = {
                "Authorization": f"Bearer {self.notion_token}",
                "Content-Type": "application/json",
                "Notion-Version": "2022-06-28",
            }

            # æ™‚é–“ç¯„å›²è¨­å®š
            since_time = datetime.now() - timedelta(hours=hours_back)
            since_iso = since_time.isoformat()

            # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            query = {
                "filter": {"property": "æ—¥ä»˜", "date": {"after": since_iso}},
                "sorts": [{"property": "æ—¥ä»˜", "direction": "descending"}],
            }

            # Notion APIå‘¼ã³å‡ºã—
            url = f"https://api.notion.com/v1/databases/{self.notion_database_id}/query"
            response = requests.post(url, headers=headers, json=query, timeout=30)

            if response.status_code == 200:
                data = response.json()
                entries = data.get("results", [])

                # æœªå‡¦ç†ã‚¨ãƒ³ãƒˆãƒªã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                new_entries = self._filter_unprocessed_entries(entries)

                self.logger.info(f"Notionã‹ã‚‰ {len(new_entries)} ä»¶ã®æ–°è¦ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—")
                return new_entries

            else:
                self.logger.error(
                    f"Notion API ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}"
                )
                return []

        except Exception as e:
            self.logger.error(f"Notionå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _filter_unprocessed_entries(
        self, entries: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """æœªå‡¦ç†ã‚¨ãƒ³ãƒˆãƒªã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        try:
            conn = sqlite3.connect(str(self.processed_db))
            cursor = conn.cursor()

            new_entries = []
            for entry in entries:
                notion_id = entry["id"]
                cursor.execute(
                    "SELECT 1 FROM processed_entries WHERE notion_id = ?", (notion_id,)
                )

                if not cursor.fetchone():
                    new_entries.append(entry)

            conn.close()
            return new_entries

        except Exception as e:
            self.logger.error(f"æœªå‡¦ç†ã‚¨ãƒ³ãƒˆãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return entries

    def classify_and_save_entry(self, entry: Dict[str, Any]) -> Optional[str]:
        """
        ã‚¨ãƒ³ãƒˆãƒªã®åˆ†é¡ã¨ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜

        Args:
            entry: Notionã‚¨ãƒ³ãƒˆãƒª

        Returns:
            ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            # ã‚¨ãƒ³ãƒˆãƒªãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            entry_data = self._extract_entry_data(entry)

            if not entry_data:
                self.logger.warning(f"ã‚¨ãƒ³ãƒˆãƒªãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {entry['id']}")
                return None

            # å“è³ªè©•ä¾¡ãƒ»åˆ†é¡
            classification = self._classify_entry(entry_data)

            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            file_path = self._save_entry_to_inbox(entry_data, classification)

            if file_path:
                # å‡¦ç†æ¸ˆã¿è¨˜éŒ²
                self._mark_as_processed(
                    entry["id"],
                    file_path,
                    classification,
                    entry_data.get("quality_score", 0.0),
                )

                self.logger.info(f"ã‚¨ãƒ³ãƒˆãƒªä¿å­˜å®Œäº†: {file_path} ({classification})")
                return file_path

            return None

        except Exception as e:
            self.logger.error(f"ã‚¨ãƒ³ãƒˆãƒªåˆ†é¡ãƒ»ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _extract_entry_data(self, entry: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Notionã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        try:
            properties = entry.get("properties", {})
            notion_id = entry.get("id", "")

            # ãƒšãƒ¼ã‚¸æœ¬æ–‡å–å¾—ï¼ˆBlocksã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
            text_content = self._fetch_page_content(notion_id)

            # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
            title = ""
            if "ã‚¿ã‚¤ãƒˆãƒ«" in properties:
                title_prop = properties["ã‚¿ã‚¤ãƒˆãƒ«"]
                if title_prop.get("title"):
                    title = title_prop["title"][0]["text"]["content"]

            # æ—¢å­˜ã®Content ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼ˆSuperWhisperç”¨ï¼‰
            content_from_property = ""
            if "Content" in properties:
                text_prop = properties["Content"]
                if text_prop["type"] == "rich_text" and text_prop["rich_text"]:
                    content_from_property = text_prop["rich_text"][0]["text"]["content"]

            # æ—¥è¨˜ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‹ã‚‰æœ¬æ–‡å–å¾—ï¼ˆè‰¯ã‹ã£ãŸã“ã¨ã€èª²é¡Œã€æ„Ÿè¬ã—ã¦ã„ã‚‹ã“ã¨ç­‰ï¼‰
            diary_content_parts = []
            diary_properties = [
                "è‰¯ã‹ã£ãŸã“ã¨",
                "èª²é¡Œ",
                "æ„Ÿè¬ã—ã¦ã„ã‚‹ã“ã¨",
                "ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯",
                "æŒ¯ã‚Šè¿”ã‚Š",
                "å­¦ã³",
                "æ°—ã¥ã",
            ]

            for prop_name in diary_properties:
                if prop_name in properties:
                    prop_data = properties[prop_name]
                    if prop_data.get("type") == "rich_text" and prop_data.get(
                        "rich_text"
                    ):
                        for text_obj in prop_data["rich_text"]:
                            content = text_obj.get("text", {}).get("content", "")
                            if content.strip():
                                diary_content_parts.append(
                                    f"**{prop_name}**\n{content}"
                                )

            # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ã®æ—¥è¨˜æœ¬æ–‡
            diary_content = (
                "\n\n".join(diary_content_parts) if diary_content_parts else ""
            )

            # æœ€çµ‚çš„ãªæœ¬æ–‡æ±ºå®šã®å„ªå…ˆé †ä½
            # 1. SuperWhisperç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆæ˜ç¤ºçš„ãªéŸ³å£°è»¢å†™ï¼‰
            # 2. ãƒšãƒ¼ã‚¸ãƒ–ãƒ­ãƒƒã‚¯æœ¬æ–‡
            # 3. æ—¥è¨˜ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®çµ„ã¿åˆã‚ã›
            # 4. ã‚¿ã‚¤ãƒˆãƒ«
            final_content = ""
            if content_from_property:
                final_content = content_from_property
            elif text_content:
                final_content = text_content
            elif diary_content:
                final_content = diary_content
            else:
                final_content = title

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            created_time = entry.get("created_time", "")

            # è»¢å†™å“è³ªè©•ä¾¡
            quality_score = self._estimate_transcription_quality(final_content)

            # éŸ³å£°å“è³ªè©•ä¾¡
            noise_level = self._estimate_noise_level(final_content)

            return {
                "notion_id": notion_id,
                "text_content": final_content,
                "title": title,
                "created_time": created_time,
                "quality_score": quality_score,
                "noise_level": noise_level,
                "text_length": len(final_content),
                "content_source": self._get_content_source(
                    content_from_property, text_content, diary_content, title
                ),
            }

        except Exception as e:
            self.logger.error(f"ã‚¨ãƒ³ãƒˆãƒªãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _get_content_source(
        self, content_property: str, page_content: str, diary_content: str, title: str
    ) -> str:
        """æœ¬æ–‡ã®å–å¾—å…ƒã‚’ç‰¹å®š"""
        if content_property:
            return "SuperWhisperéŸ³å£°è»¢å†™"
        elif page_content:
            return "Notionãƒšãƒ¼ã‚¸ãƒ–ãƒ­ãƒƒã‚¯"
        elif diary_content:
            return "æ—¥è¨˜ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£"
        else:
            return "ã‚¿ã‚¤ãƒˆãƒ«"

    def _fetch_page_content(self, page_id: str) -> str:
        """Notionãƒšãƒ¼ã‚¸ã®æœ¬æ–‡ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—"""
        try:
            headers = {
                "Authorization": f"Bearer {self.notion_token}",
                "Content-Type": "application/json",
                "Notion-Version": "2022-06-28",
            }

            return self._fetch_blocks_recursive(page_id, headers)

        except Exception as e:
            self.logger.error(f"ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ä¾‹å¤–: {e}")
            return ""

    def _fetch_blocks_recursive(self, block_id: str, headers: dict) -> str:
        """ãƒ–ãƒ­ãƒƒã‚¯ã‚’å†å¸°çš„ã«å–å¾—ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            response = requests.get(
                f"https://api.notion.com/v1/blocks/{block_id}/children", headers=headers
            )

            if response.status_code != 200:
                error_response = response.json() if response.content else {}
                error_message = error_response.get("message", "")

                # transcriptionãƒ–ãƒ­ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã™ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å–å¾—ã•ã‚Œã‚‹ï¼‰
                if "transcription is not supported" in error_message:
                    self.logger.debug(
                        f"transcriptionãƒ–ãƒ­ãƒƒã‚¯æ¤œå‡º - ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æœ¬æ–‡å–å¾—: {error_message}"
                    )
                    return ""

                self.logger.warning(
                    f"ãƒ–ãƒ­ãƒƒã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}"
                )
                return ""

            blocks = response.json().get("results", [])
            content_parts = []

            for block in blocks:
                block_type = block.get("type", "")
                block_id = block.get("id", "")

                # å„ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                text_content = self._extract_text_from_block(block, block_type)
                if text_content:
                    content_parts.append(text_content)

                # å­ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯å†å¸°çš„ã«å–å¾—
                if block.get("has_children", False):
                    child_content = self._fetch_blocks_recursive(block_id, headers)
                    if child_content:
                        content_parts.append(child_content)

            # ç©ºã§ãªã„éƒ¨åˆ†ã®ã¿çµåˆ
            filtered_parts = [part for part in content_parts if part.strip()]
            return "\n".join(filtered_parts).strip()

        except Exception as e:
            self.logger.error(f"å†å¸°çš„ãƒ–ãƒ­ãƒƒã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    def _extract_text_from_block(self, block: dict, block_type: str) -> str:
        """ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            # æ®µè½ãƒ–ãƒ­ãƒƒã‚¯
            if block_type == "paragraph":
                paragraph = block.get("paragraph", {})
                rich_text = paragraph.get("rich_text", [])
                return "\n".join(
                    [text_obj.get("plain_text", "") for text_obj in rich_text]
                )

            # è¦‹å‡ºã—ãƒ–ãƒ­ãƒƒã‚¯
            elif block_type in ["heading_1", "heading_2", "heading_3"]:
                heading = block.get(block_type, {})
                rich_text = heading.get("rich_text", [])
                level = block_type.split("_")[-1]  # 1, 2, 3
                prefix = "#" * int(level)
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"{prefix} {' '.join(texts)}"

            # ç®‡æ¡æ›¸ããƒ–ãƒ­ãƒƒã‚¯
            elif block_type == "bulleted_list_item":
                list_item = block.get("bulleted_list_item", {})
                rich_text = list_item.get("rich_text", [])
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"- {' '.join(texts)}"

            # ç•ªå·ä»˜ããƒªã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯
            elif block_type == "numbered_list_item":
                list_item = block.get("numbered_list_item", {})
                rich_text = list_item.get("rich_text", [])
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"1. {' '.join(texts)}"

            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
            elif block_type == "code":
                code_block = block.get("code", {})
                rich_text = code_block.get("rich_text", [])
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"```\n{' '.join(texts)}\n```"

            # å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯
            elif block_type == "quote":
                quote_block = block.get("quote", {})
                rich_text = quote_block.get("rich_text", [])
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"> {' '.join(texts)}"

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚ªãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            elif block_type == "table_of_contents":
                return "[ç›®æ¬¡]"

            # åŒºåˆ‡ã‚Šç·š
            elif block_type == "divider":
                return "---"

            # Toggleãƒ–ãƒ­ãƒƒã‚¯
            elif block_type == "toggle":
                toggle_block = block.get("toggle", {})
                rich_text = toggle_block.get("rich_text", [])
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"â–¶ {' '.join(texts)}"

            # Calloutãƒ–ãƒ­ãƒƒã‚¯
            elif block_type == "callout":
                callout_block = block.get("callout", {})
                rich_text = callout_block.get("rich_text", [])
                texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                return f"ğŸ’¡ {' '.join(texts)}"

            # unsupportedãƒ–ãƒ­ãƒƒã‚¯ - å­ãƒ–ãƒ­ãƒƒã‚¯ã«ä¾å­˜
            elif block_type == "unsupported":
                return ""  # å­ãƒ–ãƒ­ãƒƒã‚¯ã§å‡¦ç†ã•ã‚Œã‚‹

            # ãã®ä»–ã®ä¸æ˜ãªãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—
            else:
                # æ±ç”¨çš„ãªrich_textå–å¾—è©¦è¡Œ
                block_data = block.get(block_type, {})
                if isinstance(block_data, dict) and "rich_text" in block_data:
                    rich_text = block_data.get("rich_text", [])
                    texts = [text_obj.get("plain_text", "") for text_obj in rich_text]
                    return " ".join(texts)
                else:
                    self.logger.debug(f"æœªå¯¾å¿œãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—: {block_type}")
                    return ""

        except Exception as e:
            self.logger.error(f"ãƒ–ãƒ­ãƒƒã‚¯ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    def _estimate_transcription_quality(self, text: str) -> float:
        """è»¢å†™å“è³ªæ¨å®šï¼ˆä»®å®Ÿè£…ï¼‰"""
        try:
            if not text:
                return 0.0

            # ç°¡æ˜“å“è³ªè©•ä¾¡æŒ‡æ¨™
            quality_indicators = 0
            total_indicators = 5

            # 1. æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
            if len(text) >= self.config.get("min_text_length", 20):
                quality_indicators += 1

            # 2. å¥èª­ç‚¹å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if any(punct in text for punct in "ã€‚ã€ï¼ï¼Œ"):
                quality_indicators += 1

            # 3. ä¸æ˜æ–‡å­—ãƒã‚§ãƒƒã‚¯
            unknown_chars = text.count("ï¼Ÿ") + text.count("ã€‡") + text.count("â€»")
            if unknown_chars / len(text) < 0.1:  # 10%æœªæº€
                quality_indicators += 1

            # 4. é€£ç¶šã™ã‚‹åŒã˜æ–‡å­—ãƒã‚§ãƒƒã‚¯
            has_repetition = any(
                text[i] == text[i + 1] == text[i + 2] for i in range(len(text) - 2)
            )
            if not has_repetition:
                quality_indicators += 1

            # 5. åŸºæœ¬çš„ãªæ–‡ç« æ§‹é€ 
            if len(text.split()) >= 3:  # æœ€ä½3å˜èª
                quality_indicators += 1

            return quality_indicators / total_indicators

        except Exception as e:
            self.logger.error(f"å“è³ªæ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¸­é–“å€¤

    def _estimate_noise_level(self, text: str) -> float:
        """ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«æ¨å®šï¼ˆä»®å®Ÿè£…ï¼‰"""
        try:
            if not text:
                return 1.0  # é«˜ãƒã‚¤ã‚º

            # ãƒã‚¤ã‚ºæŒ‡æ¨™

            # æ„å‘³ä¸æ˜ãªæ–‡å­—åˆ—
            noise_chars = text.count("ã‚ãƒ¼") + text.count("ãˆãƒ¼") + text.count("ã†ãƒ¼")
            noise_ratio = noise_chars / len(text)

            return min(noise_ratio * 2, 1.0)  # 0-1ã®ç¯„å›²

        except Exception as e:
            self.logger.error(f"ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 0.5

    def _classify_entry(self, entry_data: Dict[str, Any]) -> str:
        """ã‚¨ãƒ³ãƒˆãƒªåˆ†é¡"""
        quality_threshold = self.config.get("quality_threshold", 0.9)
        min_text_length = self.config.get("min_text_length", 20)
        max_noise_level = self.config.get("max_noise_level", 0.3)

        quality_score = entry_data.get("quality_score", 0.0)
        text_length = entry_data.get("text_length", 0)
        noise_level = entry_data.get("noise_level", 1.0)

        # ğŸ’­ Personal_Thoughts/ é…ç½®æ¡ä»¶
        if (
            quality_score >= quality_threshold
            and text_length >= min_text_length
            and noise_level <= max_noise_level
        ):
            return "personal_thoughts"

        # ğŸ“¥ Inbox_Raw/ é…ç½®æ¡ä»¶
        return "inbox_raw"

    def _save_entry_to_inbox(
        self, entry_data: Dict[str, Any], classification: str
    ) -> Optional[str]:
        """ã‚¤ãƒ³ãƒœãƒƒã‚¯ã‚¹ã¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
        try:
            # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ±ºå®š
            if classification == "personal_thoughts":
                save_dir = self.personal_thoughts_dir
                prefix = "superwhisper"
            else:
                save_dir = self.inbox_raw_dir
                prefix = "superwhisper_raw"

            # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            created_time = entry_data.get("created_time", "")
            if created_time:
                dt = datetime.fromisoformat(created_time.replace("Z", "+00:00"))
                timestamp = dt.strftime("%Y%m%d_%H%M%S")
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            filename = f"{prefix}_{timestamp}.md"
            file_path = save_dir / filename

            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ä½œæˆ
            content = self._create_file_content(entry_data, classification)

            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)

            return str(file_path)

        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _create_file_content(
        self, entry_data: Dict[str, Any], classification: str
    ) -> str:
        """ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ä½œæˆï¼ˆğŸ”§æ™‚åˆ»ãƒã‚°ä¿®æ­£çµ±åˆç‰ˆï¼‰"""
        raw_created_time = entry_data.get("created_time", "")
        text_content = entry_data.get("text_content", "")
        quality_score = entry_data.get("quality_score", 0.0)
        noise_level = entry_data.get("noise_level", 0.0)
        notion_id = entry_data.get("notion_id", "")
        content_source = entry_data.get("content_source", "ä¸æ˜")

        # ğŸ”§ é‡è¦: æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¿®æ­£é©ç”¨
        fixed_created_time = self._fix_datetime_format(raw_created_time)
        datetime_validation = self._validate_datetime_quality(
            raw_created_time, fixed_created_time
        )

        # æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè¡¨ç¤ºç”¨ï¼‰
        try:
            dt = datetime.fromisoformat(fixed_created_time.replace("Z", "+00:00"))
            formatted_time = dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        except:
            formatted_time = "æ™‚åˆ»ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"

        # åˆ†é¡ãƒ©ãƒ™ãƒ«
        classification_label = (
            "ğŸ’­ Personal Thoughts"
            if classification == "personal_thoughts"
            else "ğŸ“¥ Inbox Raw"
        )

        # ä¿®æ­£æƒ…å ±ã®è¿½åŠ ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ãƒ»ä¿®æ­£é©ç”¨æ™‚ã®ã¿ï¼‰
        fix_info = ""
        if datetime_validation["is_fixed"]:
            fix_info = f"""
# ğŸ”§ æ™‚åˆ»ä¿®æ­£æƒ…å ±
- **å…ƒã®æ™‚åˆ»**: `{datetime_validation['original']}`
- **ä¿®æ­£å¾Œæ™‚åˆ»**: `{datetime_validation['fixed']}`
- **ä¿®æ­£ã‚¿ã‚¤ãƒ—**: {datetime_validation['fix_type']}
- **ä¿®æ­£æ—¥æ™‚**: {datetime.now(timezone.utc).isoformat()}

"""

        content = f"""---
source: SuperWhisper{" (Fixed)" if datetime_validation["is_fixed"] else ""}
created: {fixed_created_time}
classification: {classification_label}
quality_score: {quality_score:.2f}
noise_level: {noise_level:.2f}
notion_id: {notion_id}
personality_learning_ready: {classification == "personal_thoughts"}
content_source: {content_source}{f'''
datetime_fix_applied: {datetime_validation["is_fixed"]}
datetime_fix_type: {datetime_validation["fix_type"]}
processing_version: v2.1_datetime_fixed''' if datetime_validation["is_fixed"] else ""}
---

# SuperWhisper éŸ³å£°è¨˜éŒ²{" (æ™‚åˆ»ä¿®æ­£ç‰ˆ)" if datetime_validation["is_fixed"] else ""}

**è¨˜éŒ²æ—¥æ™‚**: {formatted_time}
**åˆ†é¡**: {classification_label}
**å“è³ªã‚¹ã‚³ã‚¢**: {quality_score:.1%}
**æœ¬æ–‡å–å¾—å…ƒ**: {content_source}

{fix_info}## éŸ³å£°å†…å®¹

{text_content}

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

- **è»¢å†™å“è³ª**: {quality_score:.1%}
- **ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«**: {noise_level:.1%}
- **æ–‡å­—æ•°**: {len(text_content)}æ–‡å­—
- **PersonalityLearningæŠ•å…¥å¯¾è±¡**: {"âœ… Yes" if classification == "personal_thoughts" else "âš ï¸ è¦ç¢ºèª"}
- **æœ¬æ–‡å–å¾—å…ƒ**: {content_source}{f'''
- **æ™‚åˆ»ä¿®æ­£é©ç”¨**: âœ… é©ç”¨æ¸ˆã¿ï¼ˆ{datetime_validation["fix_type"]}ï¼‰
- **å‡¦ç†ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v2.1_datetime_fixedï¼ˆæ™‚åˆ»ãƒã‚°ä¿®æ­£ç‰ˆï¼‰''' if datetime_validation["is_fixed"] else ""}

---
*SuperWhisper-Notionçµ±åˆã‚·ã‚¹ãƒ†ãƒ {"ï¼ˆæ™‚åˆ»ä¿®æ­£ç‰ˆï¼‰" if datetime_validation["is_fixed"] else ""}è‡ªå‹•ç”Ÿæˆ*
"""

        return content

    def _mark_as_processed(
        self, notion_id: str, file_path: str, classification: str, quality_score: float
    ):
        """å‡¦ç†æ¸ˆã¿ãƒãƒ¼ã‚¯"""
        try:
            conn = sqlite3.connect(str(self.processed_db))
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT OR REPLACE INTO processed_entries
                (notion_id, file_path, classification, quality_score)
                VALUES (?, ?, ?, ?)
            """,
                (notion_id, file_path, classification, quality_score),
            )

            conn.commit()
            conn.close()

        except Exception as e:
            self.logger.error(f"å‡¦ç†æ¸ˆã¿ãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

    def monitor_and_process(self, single_run: bool = False) -> int:
        """
        ç¶™ç¶šç›£è¦–ãƒ»å‡¦ç†å®Ÿè¡Œ

        Args:
            single_run: ä¸€å›ã®ã¿å®Ÿè¡Œã™ã‚‹ã‹

        Returns:
            å‡¦ç†ä»¶æ•°
        """
        processed_count = 0

        try:
            self.logger.info("SuperWhisper-Notionç›£è¦–é–‹å§‹")

            while True:
                try:
                    # Notionã‹ã‚‰æ–°è¦ã‚¨ãƒ³ãƒˆãƒªå–å¾—
                    entries = self.fetch_notion_entries()

                    # ã‚¨ãƒ³ãƒˆãƒªå‡¦ç†
                    for entry in entries:
                        file_path = self.classify_and_save_entry(entry)
                        if file_path:
                            processed_count += 1

                    if entries:
                        self.logger.info(f"ãƒãƒƒãƒå‡¦ç†å®Œäº†: {len(entries)}ä»¶å‡¦ç†")

                    # ä¸€å›ã®ã¿å®Ÿè¡Œã®å ´åˆã¯çµ‚äº†
                    if single_run:
                        break

                    # ç›£è¦–é–“éš”å¾…æ©Ÿ
                    interval = self.config.get("monitor_interval", 300)
                    self.logger.debug(f"{interval}ç§’å¾…æ©Ÿä¸­...")
                    time.sleep(interval)

                except KeyboardInterrupt:
                    self.logger.info("ç›£è¦–åœæ­¢ãŒè¦æ±‚ã•ã‚Œã¾ã—ãŸ")
                    break
                except Exception as e:
                    self.logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ

            self.logger.info(f"ç›£è¦–çµ‚äº† - ç·å‡¦ç†ä»¶æ•°: {processed_count}")
            return processed_count

        except Exception as e:
            self.logger.error(f"ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
            return processed_count


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="SuperWhisper-Notionçµ±åˆã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--single-run", action="store_true", help="ä¸€å›ã®ã¿å®Ÿè¡Œ")
    parser.add_argument("--config", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")

    args = parser.parse_args()

    try:
        integration = SuperWhisperNotionIntegration(args.config)
        processed_count = integration.monitor_and_process(single_run=args.single_run)

        print(f"âœ… å‡¦ç†å®Œäº†: {processed_count}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‡¦ç†ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
