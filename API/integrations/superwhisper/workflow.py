#!/usr/bin/env python3
"""
SuperWhisper è‡ªå‹•å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆMIRRALISM V2ï¼‰
=============================================

å®Œå…¨è‡ªå‹•åŒ–ãƒ•ãƒ­ãƒ¼:
1. SuperWhisperéŸ³å£°ãƒ‡ãƒ¼ã‚¿æ¤œçŸ¥
2. æ™‚åˆ»ãƒã‚°ä¿®æ­£ + PersonalityLearningçµ±åˆåˆ†æ
3. TaskMasteré€£æºï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
4. åˆ†é¡åˆ¥ãƒ‡ãƒ¼ã‚¿ä¿å­˜
5. é€²åŒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°

ä½œæˆè€…: MIRRALISMçµ±åˆãƒãƒ¼ãƒ 
ä½œæˆæ—¥: 2025å¹´6æœˆ3æ—¥
"""

import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any
from typing import Dict
from typing import List
from typing import Optional

# MIRRALISMçµ±åˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent))
from core import SuperWhisperMirralismIntegration

# TaskMasterçµ±åˆæº–å‚™
try:
    sys.path.append(str(Path(__file__).parent.parent.parent.parent))
    # TaskMasterçµ±åˆã¯å¾Œã®ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…
    TASKMASTER_AVAILABLE = False
except ImportError:
    TASKMASTER_AVAILABLE = False


class SuperWhisperAutoWorkflow:
    """SuperWhisperè‡ªå‹•å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""

    def __init__(self, project_root: Optional[Path] = None):
        """
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆæœŸåŒ–

        Args:
            project_root: MIRRALISMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        """
        self.project_root = project_root or Path(__file__).parent.parent.parent.parent
        self.integration = SuperWhisperMirralismIntegration(self.project_root)
        self.setup_logging()

        # å‡¦ç†çµ±è¨ˆ
        self.session_stats = {
            "processed_count": 0,
            "success_count": 0,
            "error_count": 0,
            "personality_learning_updates": 0,
            "task_correlations": 0,
            "session_start": datetime.now().isoformat(),
        }

        self.logger.info("ğŸš€ SuperWhisperè‡ªå‹•ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹")

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        )
        self.logger = logging.getLogger(__name__)

    def process_audio_input(self, audio_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        éŸ³å£°å…¥åŠ›ã®å®Œå…¨è‡ªå‹•å‡¦ç†

        Args:
            audio_data: SuperWhisperã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿

        Returns:
            å‡¦ç†çµæœ
        """
        self.session_stats["processed_count"] += 1
        process_id = f"auto_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        try:
            self.logger.info(f"ğŸ¤ éŸ³å£°å‡¦ç†é–‹å§‹: {process_id}")

            # Phase 1: åŸºæœ¬çµ±åˆå‡¦ç†
            integration_result = self.integration.process_voice_input(
                audio_data,
                classification=self._classify_audio_content(audio_data),
            )

            if not integration_result["success"]:
                raise Exception(f"çµ±åˆå‡¦ç†å¤±æ•—: {integration_result.get('error', 'unknown')}")

            # Phase 2: PersonalityLearningåˆ†ææ‹¡å¼µ
            enhanced_analysis = self._enhance_personality_analysis(
                integration_result["integrated_data"]
            )

            # Phase 3: TaskMasterç›¸é–¢åˆ†æï¼ˆPhase 3ã§å®Ÿè£…ï¼‰
            task_correlation = self._analyze_task_correlation(enhanced_analysis)

            # Phase 4: è‡ªå‹•åˆ†é¡ãƒ»ä¿å­˜
            final_result = self._finalize_processing(
                enhanced_analysis, task_correlation, process_id
            )

            # çµ±è¨ˆæ›´æ–°
            self.session_stats["success_count"] += 1
            if enhanced_analysis.get("personality_learning_updated", False):
                self.session_stats["personality_learning_updates"] += 1
            if task_correlation.get("correlation_found", False):
                self.session_stats["task_correlations"] += 1

            self.logger.info(f"âœ… éŸ³å£°å‡¦ç†å®Œäº†: {process_id}")

            return {
                "success": True,
                "process_id": process_id,
                "integration_result": integration_result,
                "enhanced_analysis": enhanced_analysis,
                "task_correlation": task_correlation,
                "final_result": final_result,
                "session_stats": self.session_stats,
            }

        except Exception as e:
            self.session_stats["error_count"] += 1
            self.logger.error(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({process_id}): {e}")

            return {
                "success": False,
                "process_id": process_id,
                "error": str(e),
                "audio_data": audio_data,
                "session_stats": self.session_stats,
            }

    def _classify_audio_content(self, audio_data: Dict[str, Any]) -> str:
        """
        éŸ³å£°å†…å®¹ã®è‡ªå‹•åˆ†é¡

        Args:
            audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿

        Returns:
            åˆ†é¡çµæœ (thought, task, idea, reflection, etc.)
        """
        text_content = audio_data.get("text_content", "").lower()

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†é¡
        task_keywords = [
            "ã‚¿ã‚¹ã‚¯",
            "ã‚„ã‚‹ã“ã¨",
            "todo",
            "ã™ã‚‹å¿…è¦",
            "å®Ÿè£…",
            "ä½œæ¥­",
        ]
        idea_keywords = ["ã‚¢ã‚¤ãƒ‡ã‚¢", "è€ƒãˆ", "æ€ã„ã¤ã", "ã²ã‚‰ã‚ã", "ç™ºæƒ³"]
        reflection_keywords = ["æŒ¯ã‚Šè¿”ã‚Š", "åçœ", "å­¦ã³", "æ°—ã¥ã", "æ„Ÿæƒ³"]

        # åˆ†é¡åˆ¤å®š
        if any(keyword in text_content for keyword in task_keywords):
            return "task"
        elif any(keyword in text_content for keyword in idea_keywords):
            return "idea"
        elif any(keyword in text_content for keyword in reflection_keywords):
            return "reflection"
        else:
            return "thought"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    def _enhance_personality_analysis(
        self, integrated_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        PersonalityLearningåˆ†æã®æ‹¡å¼µå‡¦ç†

        Args:
            integrated_data: çµ±åˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿

        Returns:
            æ‹¡å¼µåˆ†æçµæœ
        """
        enhanced = integrated_data.copy()

        # PersonalityLearningçµæœã®è©³ç´°åˆ†æ
        analysis_result = enhanced.get("analysis_result")
        if analysis_result and analysis_result.get("success"):
            # ç²¾åº¦é€²åŒ–ãƒã‚§ãƒƒã‚¯
            confidence = analysis_result.get("confidence", 0.0)
            evolution_status = analysis_result.get("evolution_status", {})

            # å­¦ç¿’åŠ¹æœæŒ‡æ¨™è¨ˆç®—
            learning_impact = self._calculate_learning_impact(
                confidence, evolution_status
            )

            enhanced["personality_learning_enhanced"] = {
                "learning_impact": learning_impact,
                "confidence_score": confidence,
                "evolution_stage": evolution_status.get("current_stage", "unknown"),
                "voice_weight_applied": True,
                "analysis_timestamp": datetime.now().isoformat(),
            }

            # é«˜ç²¾åº¦åˆ¤å®š
            if confidence > 80.0:
                enhanced["high_confidence_analysis"] = True
                enhanced["personality_learning_updated"] = True
                self.logger.info(f"ğŸ¯ é«˜ç²¾åº¦åˆ†æé”æˆ: {confidence}%")

        return enhanced

    def _calculate_learning_impact(
        self, confidence: float, evolution_status: Dict
    ) -> float:
        """
        å­¦ç¿’åŠ¹æœå½±éŸ¿åº¦è¨ˆç®—

        Args:
            confidence: åˆ†æç²¾åº¦
            evolution_status: é€²åŒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

        Returns:
            å­¦ç¿’å½±éŸ¿åº¦ (0.0-1.0)
        """
        base_impact = confidence / 100.0

        # é€²åŒ–ã‚¹ãƒ†ãƒ¼ã‚¸ãƒœãƒ¼ãƒŠã‚¹
        stage_bonus = 0.0
        if evolution_status.get("stage_updated", False):
            stage_bonus = 0.2

        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãƒœãƒ¼ãƒŠã‚¹ï¼ˆ1.5å€é‡ã¿ä»˜ã‘åæ˜ ï¼‰
        voice_bonus = 0.1

        return min(1.0, base_impact + stage_bonus + voice_bonus)

    def _analyze_task_correlation(
        self, enhanced_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        TaskMasterç›¸é–¢åˆ†æï¼ˆPhase 3ã§è©³ç´°å®Ÿè£…ï¼‰

        Args:
            enhanced_data: æ‹¡å¼µåˆ†æãƒ‡ãƒ¼ã‚¿

        Returns:
            TaskMasterç›¸é–¢çµæœ
        """
        # ç¾åœ¨ã¯åŸºæœ¬çš„ãªç›¸é–¢æ¤œçŸ¥ã®ã¿
        classification = enhanced_data.get("classification", "thought")
        text_content = enhanced_data.get("text_content", "")

        correlation_result = {
            "correlation_found": False,
            "suggested_actions": [],
            "task_keywords": [],
            "classification": classification,
        }

        # ã‚¿ã‚¹ã‚¯é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥
        if classification == "task":
            task_keywords = self._extract_task_keywords(text_content)
            if task_keywords:
                correlation_result.update(
                    {
                        "correlation_found": True,
                        "task_keywords": task_keywords,
                        "suggested_actions": [
                            "TaskMasteræ–°è¦ã‚¿ã‚¹ã‚¯ä½œæˆã‚’æ¤œè¨",
                            "æ—¢å­˜ã‚¿ã‚¹ã‚¯ã¨ã®é–¢é€£æ€§ç¢ºèª",
                        ],
                    }
                )

        return correlation_result

    def _extract_task_keywords(self, text_content: str) -> List[str]:
        """
        ã‚¿ã‚¹ã‚¯é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º

        Args:
            text_content: ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹

        Returns:
            æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        """
        keywords = []
        task_patterns = [
            "å®Ÿè£…",
            "ä½œæˆ",
            "ä¿®æ­£",
            "æ›´æ–°",
            "è¿½åŠ ",
            "å‰Šé™¤",
            "ãƒ†ã‚¹ãƒˆ",
            "ãƒ‡ãƒ—ãƒ­ã‚¤",
            "è¨­è¨ˆ",
            "åˆ†æ",
            "æ¤œè¨¼",
            "ãƒ¬ãƒ“ãƒ¥ãƒ¼",
        ]

        for pattern in task_patterns:
            if pattern in text_content:
                keywords.append(pattern)

        return keywords

    def _finalize_processing(
        self,
        enhanced_data: Dict[str, Any],
        task_correlation: Dict[str, Any],
        process_id: str,
    ) -> Dict[str, Any]:
        """
        å‡¦ç†æœ€çµ‚åŒ–

        Args:
            enhanced_data: æ‹¡å¼µåˆ†æãƒ‡ãƒ¼ã‚¿
            task_correlation: TaskMasterç›¸é–¢ãƒ‡ãƒ¼ã‚¿
            process_id: å‡¦ç†ID

        Returns:
            æœ€çµ‚å‡¦ç†çµæœ
        """
        final_data = {
            **enhanced_data,
            "task_correlation": task_correlation,
            "process_id": process_id,
            "workflow_version": "v2.1_auto",
            "finalized_timestamp": datetime.now().isoformat(),
        }

        # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼
        summary = {
            "classification": enhanced_data.get("classification", "unknown"),
            "personality_learning_confidence": enhanced_data.get(
                "analysis_result", {}
            ).get("confidence", 0.0),
            "task_correlation_found": task_correlation.get("correlation_found", False),
            "learning_impact": enhanced_data.get(
                "personality_learning_enhanced", {}
            ).get("learning_impact", 0.0),
            "process_id": process_id,
        }

        final_data["processing_summary"] = summary

        # è¿½åŠ ä¿å­˜ï¼ˆè©³ç´°ãƒ­ã‚°ï¼‰
        self._save_processing_log(final_data)

        return final_data

    def _save_processing_log(self, final_data: Dict[str, Any]):
        """
        å‡¦ç†ãƒ­ã‚°ä¿å­˜

        Args:
            final_data: æœ€çµ‚å‡¦ç†ãƒ‡ãƒ¼ã‚¿
        """
        try:
            log_dir = self.project_root / "Data" / "processing_logs"
            log_dir.mkdir(parents=True, exist_ok=True)

            log_file = (
                log_dir / f"superwhisper_workflow_{final_data['process_id']}.json"
            )

            with open(log_file, "w", encoding="utf-8") as f:
                json.dump(final_data, f, ensure_ascii=False, indent=2, default=str)

            self.logger.info(f"ğŸ“ å‡¦ç†ãƒ­ã‚°ä¿å­˜: {log_file}")

        except Exception as e:
            self.logger.error(f"âŒ å‡¦ç†ãƒ­ã‚°ä¿å­˜å¤±æ•—: {e}")

    def get_session_summary(self) -> Dict[str, Any]:
        """
        ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„å–å¾—

        Returns:
            ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
        """
        session_duration = (
            datetime.now() - datetime.fromisoformat(self.session_stats["session_start"])
        ).total_seconds()

        return {
            **self.session_stats,
            "session_duration_seconds": session_duration,
            "success_rate": (
                self.session_stats["success_count"]
                / max(1, self.session_stats["processed_count"])
            )
            * 100,
            "integration_status": self.integration.get_integration_status(),
        }


# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
def process_superwhisper_input(audio_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    SuperWhisperå…¥åŠ›ã®è‡ªå‹•å‡¦ç†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

    Args:
        audio_data: SuperWhisperã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿

    Returns:
        å‡¦ç†çµæœ
    """
    workflow = SuperWhisperAutoWorkflow()
    return workflow.process_audio_input(audio_data)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_audio = {
        "text_content": "MIRRALISMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®PersonalityLearningçµ±åˆã‚’å®Œäº†ã•ã›ã‚‹å¿…è¦ãŒã‚ã‚‹",
        "created_time": "2025-06-03T19:30:00+09:00",
        "notion_id": "test_123",
        "quality_score": 0.95,
    }

    result = process_superwhisper_input(test_audio)

    print("ğŸš€ SuperWhisperè‡ªå‹•ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    print(f"æˆåŠŸ: {result['success']}")
    if result["success"]:
        summary = result["final_result"]["processing_summary"]
        print(f"åˆ†é¡: {summary['classification']}")
        print(f"PersonalityLearningç²¾åº¦: {summary['personality_learning_confidence']}%")
        print(f"TaskMasterç›¸é–¢: {summary['task_correlation_found']}")
        print(f"å­¦ç¿’å½±éŸ¿åº¦: {summary['learning_impact']:.2f}")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")
