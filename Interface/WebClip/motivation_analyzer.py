#!/usr/bin/env python3
"""
WebClipå‹•æ©Ÿåˆ†æã‚¨ãƒ³ã‚¸ãƒ³
====================

MIRRALISM V2 WebClipç‹¬ç«‹ã‚·ã‚¹ãƒ†ãƒ 
ç›®çš„: ã‚¯ãƒªãƒƒãƒ—å‹•æ©Ÿã®æ·±ã„ç†è§£ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ´å¯Ÿç”Ÿæˆ

ä½œæˆè€…: æŠ€è¡“è²¬ä»»è€…
ä½œæˆæ—¥: 2025å¹´6æœˆ6æ—¥
è¨­è¨ˆæ€æƒ³: Option B åˆ†é›¢æœ€é©åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
"""

import json
import logging
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import yaml


class WebClipMotivationAnalyzer:
    """WebClipã‚¯ãƒªãƒƒãƒ—å‹•æ©Ÿåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, project_root: Optional[Path] = None):
        """
        å‹•æ©Ÿåˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        
        Args:
            project_root: MIRRALISMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        """
        self.project_root = project_root or Path(__file__).parent.parent.parent
        self.setup_logging()
        
        # å‹•æ©Ÿãƒ‘ã‚¿ãƒ¼ãƒ³DB
        self.motivation_patterns = self._load_motivation_patterns()
        
        # èˆˆå‘³è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ 
        self.interest_history = self._load_interest_history()
        
        self.logger.info("âœ… WebClipå‹•æ©Ÿåˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - WEBCLIP_MOTIVATION - %(levelname)s - %(message)s"
        )
        self.logger = logging.getLogger(__name__)

    def analyze_clip_motivation(
        self, 
        article_content: str, 
        article_url: str, 
        article_title: str,
        user_context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ã‚¯ãƒªãƒƒãƒ—å‹•æ©Ÿåˆ†æ
        
        CTOã®è¦æ±‚: ã€Œã‚ãªãŸã¯ã“ã†ã„ã†ã“ã¨ã«èˆˆå‘³ã‚’æŒã£ãŸã‚“ã§ã™ã­ã€
        ã€Œãªãœã“ã®è¨˜äº‹ã‚’ã‚¯ãƒªãƒƒãƒ—ã—ãŸã®ã‹ï¼Ÿã€
        
        Args:
            article_content: è¨˜äº‹å†…å®¹
            article_url: è¨˜äº‹URL
            article_title: è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            user_context: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            å‹•æ©Ÿåˆ†æçµæœ
        """
        try:
            # 1. å†…å®¹åˆ†æ
            content_analysis = self._analyze_content_themes(article_content, article_title)
            
            # 2. èˆˆå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            interest_analysis = self._analyze_interest_patterns(content_analysis)
            
            # 3. å‹•æ©Ÿæ¨å®š
            motivation_estimation = self._estimate_motivation(
                content_analysis, interest_analysis, user_context
            )
            
            # 4. è³ªå•ç”Ÿæˆ
            questions = self._generate_motivation_questions(motivation_estimation)
            
            # 5. æ´»ç”¨ææ¡ˆ
            utilization_suggestions = self._suggest_utilization(motivation_estimation)
            
            analysis_result = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "article_info": {
                    "title": article_title,
                    "url": article_url,
                    "content_length": len(article_content)
                },
                "content_analysis": content_analysis,
                "interest_analysis": interest_analysis,
                "motivation_estimation": motivation_estimation,
                "dialogue": {
                    "interest_insight": self._generate_interest_insight(interest_analysis),
                    "motivation_questions": questions,
                    "follow_up_questions": self._generate_follow_up_questions(motivation_estimation)
                },
                "utilization_suggestions": utilization_suggestions,
                "confidence_score": self._calculate_confidence(motivation_estimation)
            }
            
            # 6. èˆˆå‘³å±¥æ­´æ›´æ–°
            self._update_interest_history(interest_analysis)
            
            self.logger.info(f"âœ… ã‚¯ãƒªãƒƒãƒ—å‹•æ©Ÿåˆ†æå®Œäº†: {article_title[:50]}...")
            
            return {
                "success": True,
                "analysis": analysis_result
            }
            
        except Exception as e:
            import traceback
            self.logger.error(f"âŒ ã‚¯ãƒªãƒƒãƒ—å‹•æ©Ÿåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "article_title": article_title
            }

    def _analyze_content_themes(self, content: str, title: str) -> Dict[str, Any]:
        """è¨˜äº‹å†…å®¹ã®ãƒ†ãƒ¼ãƒåˆ†æ"""
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = self._extract_keywords(content + " " + title)
        
        # ãƒ†ãƒ¼ãƒåˆ†é¡
        themes = self._classify_themes(keywords, content)
        
        # å†…å®¹ã‚¿ã‚¤ãƒ—åˆ¤å®š
        content_type = self._determine_content_type(content, title)
        
        return {
            "keywords": keywords,
            "themes": themes,
            "content_type": content_type,
            "complexity_level": self._assess_complexity(content),
            "actionability": self._assess_actionability(content)
        }

    def _analyze_interest_patterns(self, content_analysis: Dict) -> Dict[str, Any]:
        """èˆˆå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        
        current_themes = content_analysis["themes"]
        
        # éå»ã®èˆˆå‘³å±¥æ­´ã¨æ¯”è¼ƒ
        recent_interests = self._get_recent_interests(days=30)
        theme_frequency = self._calculate_theme_frequency(current_themes, recent_interests)
        
        # èˆˆå‘³ã®å¤‰åŒ–åˆ†æ
        interest_trend = self._analyze_interest_trend(current_themes, recent_interests)
        
        # æ–°è¦æ€§è©•ä¾¡
        novelty_score = self._calculate_novelty(current_themes, recent_interests)
        
        return {
            "current_themes": current_themes,
            "theme_frequency": theme_frequency,
            "interest_trend": interest_trend,
            "novelty_score": novelty_score,
            "interest_intensity": self._calculate_interest_intensity(theme_frequency),
            "related_past_clips": self._find_related_clips(current_themes)
        }

    def _estimate_motivation(
        self, 
        content_analysis: Dict, 
        interest_analysis: Dict,
        user_context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """å‹•æ©Ÿæ¨å®š"""
        
        motivations = []
        
        # å­¦ç¿’å‹•æ©Ÿ
        if content_analysis["content_type"] in ["educational", "tutorial", "guide"]:
            motivations.append({
                "type": "learning",
                "reason": "æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚„çŸ¥è­˜ã‚’ç¿’å¾—ã—ãŸã„",
                "confidence": 0.8,
                "evidence": content_analysis["content_type"]
            })
        
        # å®Ÿè·µå‹•æ©Ÿ  
        if content_analysis["actionability"] > 0.7:
            motivations.append({
                "type": "practical",
                "reason": "å®Ÿéš›ã®æ¥­å‹™ã‚„æ´»å‹•ã«æ´»ç”¨ã—ãŸã„", 
                "confidence": content_analysis["actionability"],
                "evidence": "é«˜ã„å®Ÿè¡Œå¯èƒ½æ€§"
            })
        
        # æ¢ç©¶å‹•æ©Ÿ
        if interest_analysis["novelty_score"] > 0.6:
            motivations.append({
                "type": "exploration", 
                "reason": "æ–°ã—ã„åˆ†é‡ã¸ã®é–¢å¿ƒã‹ã‚‰",
                "confidence": interest_analysis["novelty_score"],
                "evidence": "æ–°è¦æ€§ã®é«˜ã„ãƒ†ãƒ¼ãƒ"
            })
        
        # ç¶™ç¶šå‹•æ©Ÿ
        if interest_analysis["theme_frequency"].get("max_frequency", 0) > 3:
            motivations.append({
                "type": "continuation",
                "reason": "ç¶™ç¶šçš„ã«é–¢å¿ƒã‚’æŒã£ã¦ã„ã‚‹åˆ†é‡ã®æ·±æ˜ã‚Š",
                "confidence": 0.7,
                "evidence": "éå»ã®é–¢å¿ƒå±¥æ­´"
            })
        
        # MIRRALISMé–¢é€£å‹•æ©Ÿ
        mirralism_relevance = self._assess_mirralism_relevance(content_analysis)
        if mirralism_relevance > 0.5:
            motivations.append({
                "type": "mirralism_application",
                "reason": "MIRRALISMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å¿œç”¨ã§ããã†",
                "confidence": mirralism_relevance,
                "evidence": "MIRRALISMé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"
            })
        
        # æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„å‹•æ©Ÿã‚’ç‰¹å®š
        primary_motivation = max(motivations, key=lambda x: x["confidence"]) if motivations else None
        
        return {
            "all_motivations": motivations,
            "primary_motivation": primary_motivation,
            "motivation_diversity": len(motivations),
            "overall_confidence": max([m["confidence"] for m in motivations]) if motivations else 0.3
        }

    def _generate_interest_insight(self, interest_analysis: Dict) -> str:
        """èˆˆå‘³æ´å¯Ÿãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
        
        current_themes = interest_analysis["current_themes"]
        interest_trend = interest_analysis["interest_trend"]
        
        if not current_themes:
            return "ã“ã®è¨˜äº‹ã«èˆˆå‘³ã‚’æŒãŸã‚ŒãŸã‚“ã§ã™ã­"
        
        # æœ€ã‚‚é¡•è‘—ãªãƒ†ãƒ¼ãƒ
        primary_theme = current_themes[0] if current_themes else "ã“ã®ãƒ†ãƒ¼ãƒ"
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±
        if interest_trend.get("trending_up"):
            trend_info = f"æœ€è¿‘ã€Œ{primary_theme}ã€ã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã­"
        elif interest_trend.get("consistent"):
            trend_info = f"ç¶™ç¶šçš„ã«ã€Œ{primary_theme}ã€ã«èˆˆå‘³ã‚’ãŠæŒã¡ã§ã™ã­"
        else:
            trend_info = f"ã€Œ{primary_theme}ã€ã«èˆˆå‘³ã‚’æŒãŸã‚ŒãŸã‚“ã§ã™ã­"
        
        # é »åº¦æƒ…å ±
        frequency = interest_analysis["theme_frequency"].get("max_frequency", 0)
        if frequency > 5:
            frequency_info = f"ï¼ˆä»Šæœˆ{frequency}å›ç›®ã®ã‚¯ãƒªãƒƒãƒ—ã§ã™ï¼‰"
        elif frequency > 2:
            frequency_info = f"ï¼ˆä»Šæœˆ{frequency}å›ç›®ã§ã™ã­ï¼‰"
        else:
            frequency_info = ""
        
        return f"{trend_info}{frequency_info}"

    def _generate_motivation_questions(self, motivation_estimation: Dict) -> List[str]:
        """å‹•æ©Ÿç¢ºèªè³ªå•ç”Ÿæˆ"""
        
        questions = []
        primary = motivation_estimation.get("primary_motivation")
        
        if not primary:
            return ["ã“ã®è¨˜äº‹ã‚’ã‚¯ãƒªãƒƒãƒ—ã•ã‚ŒãŸã®ã¯ã©ã®ã‚ˆã†ãªç†ç”±ã‹ã‚‰ã§ã—ã‚‡ã†ã‹ï¼Ÿ"]
        
        motivation_type = primary["type"]
        
        question_templates = {
            "learning": [
                "æ–°ã—ã„çŸ¥è­˜ã‚„ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã™ã‚‹ãŸã‚ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
                "å­¦ç¿’ç›®çš„ã§ã‚¯ãƒªãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ"
            ],
            "practical": [
                "å®Ÿéš›ã®æ¥­å‹™ã‚„æ´»å‹•ã«æ´»ç”¨ã™ã‚‹äºˆå®šã§ã™ã‹ï¼Ÿ",
                "å…·ä½“çš„ãªå®Ÿè·µã‚’æƒ³å®šã—ã¦ã‚¯ãƒªãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ"
            ],
            "exploration": [
                "æ–°ã—ã„åˆ†é‡ã¸ã®èˆˆå‘³ã‹ã‚‰ã‚¯ãƒªãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ",
                "ã“ã®åˆ†é‡ã‚’ã‚‚ã£ã¨æ¢æ±‚ã—ãŸã„ã¨æ€ã‚ã‚Œã¾ã—ãŸã‹ï¼Ÿ"
            ],
            "continuation": [
                "ç¶™ç¶šçš„ã«é–¢å¿ƒã‚’ãŠæŒã¡ã®åˆ†é‡ã§ã™ãŒã€ä»Šå›ã¯ä½•ã‹æ–°ã—ã„è¦³ç‚¹ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ",
                "ã“ã®åˆ†é‡ã®ç†è§£ã‚’ã•ã‚‰ã«æ·±ã‚ãŸã„ã¨ãŠè€ƒãˆã§ã™ã‹ï¼Ÿ"
            ],
            "mirralism_application": [
                "MIRRALISMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å¿œç”¨ã§ããã†ã ã¨æ„Ÿã˜ã‚‰ã‚Œã¾ã—ãŸã‹ï¼Ÿ",
                "MIRRALISM ã®è¨­è¨ˆã‚„æˆ¦ç•¥ã«å‚è€ƒã«ãªã‚Šãã†ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
            ]
        }
        
        questions.extend(question_templates.get(motivation_type, ["ã“ã®è¨˜äº‹ã‚’ã‚¯ãƒªãƒƒãƒ—ã•ã‚ŒãŸç†ç”±ã‚’æ•™ãˆã¦ãã ã•ã„"]))
        
        return questions[:2]  # æœ€å¤§2ã¤ã®è³ªå•

    def _generate_follow_up_questions(self, motivation_estimation: Dict) -> List[str]:
        """ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ç”Ÿæˆ"""
        
        return [
            "ã“ã®è¨˜äº‹ã‚’ã©ã®ã‚ˆã†ã«æ´»ç”¨ã™ã‚‹äºˆå®šã§ã™ã‹ï¼Ÿ",
            "èª­ã¿è¿”ã™ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯ã„ã¤é ƒã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            "é¡ä¼¼ã®ãƒ†ãƒ¼ãƒã§ä»–ã«çŸ¥ã‚ŠãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
        ]

    def _suggest_utilization(self, motivation_estimation: Dict) -> List[Dict[str, str]]:
        """æ´»ç”¨ææ¡ˆç”Ÿæˆ"""
        
        suggestions = []
        primary = motivation_estimation.get("primary_motivation")
        
        if not primary:
            return [{"type": "general", "suggestion": "å¾Œæ—¥ã˜ã£ãã‚Šèª­ã¿è¿”ã™ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"}]
        
        motivation_type = primary["type"]
        
        suggestion_templates = {
            "learning": [
                {"type": "action", "suggestion": "é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ¡ãƒ¢ã—ãªãŒã‚‰èª­ã¿è¿”ã™"},
                {"type": "schedule", "suggestion": "å­¦ç¿’æ™‚é–“ã‚’ç¢ºä¿ã—ã¦é›†ä¸­çš„ã«èª­ã‚€"},
                {"type": "practice", "suggestion": "å­¦ã‚“ã å†…å®¹ã‚’å®Ÿéš›ã«è©¦ã—ã¦ã¿ã‚‹"}
            ],
            "practical": [
                {"type": "action", "suggestion": "å…·ä½“çš„ãªå®Ÿè¡Œè¨ˆç”»ã‚’ç«‹ã¦ã‚‹"},
                {"type": "integration", "suggestion": "ç¾åœ¨ã®æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ã¸ã®çµ„ã¿è¾¼ã¿ã‚’æ¤œè¨"},
                {"type": "test", "suggestion": "å°è¦æ¨¡ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚’è©¦ã—ã¦ã¿ã‚‹"}
            ],
            "exploration": [
                {"type": "research", "suggestion": "é–¢é€£è¨˜äº‹ã‚„æ›¸ç±ã‚’ã•ã‚‰ã«æ¢ã™"},
                {"type": "connection", "suggestion": "æ—¢å­˜ã®çŸ¥è­˜ã¨ã®é–¢é€£æ€§ã‚’è€ƒãˆã‚‹"},
                {"type": "discussion", "suggestion": "å°‚é–€å®¶ã‚„åŒåƒšã¨è­°è«–ã—ã¦ã¿ã‚‹"}
            ],
            "mirralism_application": [
                {"type": "analysis", "suggestion": "MIRRALISMè¨­è¨ˆã¸ã®é©ç”¨å¯èƒ½æ€§ã‚’åˆ†æ"},
                {"type": "documentation", "suggestion": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè³‡æ–™ã¨ã—ã¦æ•´ç†ãƒ»ä¿å­˜"},
                {"type": "team_share", "suggestion": "ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã¨çŸ¥è¦‹ã‚’å…±æœ‰"}
            ]
        }
        
        suggestions.extend(suggestion_templates.get(motivation_type, []))
        
        return suggestions[:3]  # æœ€å¤§3ã¤ã®ææ¡ˆ

    def _extract_keywords(self, text: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªNLPä½¿ç”¨äºˆå®šï¼‰
        words = re.findall(r'\b[a-zA-Zã‚-ã‚“ä¸€-é¾¯]{3,}\b', text.lower())
        
        # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ç‰¹å®šï¼ˆé »åº¦ã¨ä½ç½®ãƒ™ãƒ¼ã‚¹ï¼‰
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # é »åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        return [word for word, freq in sorted_words[:10]]

    def _classify_themes(self, keywords: List[str], content: str) -> List[str]:
        """ãƒ†ãƒ¼ãƒåˆ†é¡"""
        
        theme_keywords = {
            "technology": ["ai", "machine learning", "programming", "software", "tech", "digital"],
            "management": ["management", "leadership", "strategy", "team", "organization"],
            "business": ["business", "startup", "marketing", "sales", "revenue", "growth"],
            "design": ["design", "ui", "ux", "interface", "user experience"],
            "productivity": ["productivity", "efficiency", "workflow", "process", "automation"],
            "learning": ["learning", "education", "skill", "knowledge", "training"],
            "health": ["health", "wellness", "fitness", "mental", "physical"],
            "finance": ["finance", "investment", "money", "financial", "economics"]
        }
        
        themes = []
        content_lower = content.lower()
        
        for theme, theme_words in theme_keywords.items():
            if any(word in content_lower or word in keywords for word in theme_words):
                themes.append(theme)
        
        return themes

    def _determine_content_type(self, content: str, title: str) -> str:
        """å†…å®¹ã‚¿ã‚¤ãƒ—åˆ¤å®š"""
        
        combined_text = (content + " " + title).lower()
        
        if any(word in combined_text for word in ["how to", "tutorial", "guide", "step by step"]):
            return "tutorial"
        elif any(word in combined_text for word in ["news", "announcement", "breaking", "update"]):
            return "news"
        elif any(word in combined_text for word in ["analysis", "research", "study", "report"]):
            return "analysis"
        elif any(word in combined_text for word in ["opinion", "thought", "perspective", "view"]):
            return "opinion"
        elif any(word in combined_text for word in ["case study", "example", "implementation"]):
            return "case_study"
        else:
            return "informational"

    def _assess_complexity(self, content: str) -> float:
        """è¤‡é›‘åº¦è©•ä¾¡"""
        
        # ç°¡æ˜“çš„ãªè¤‡é›‘åº¦è©•ä¾¡
        technical_terms = len(re.findall(r'\b[A-Z]{2,}\b', content))  # å°‚é–€ç”¨èªï¼ˆå¤§æ–‡å­—ï¼‰
        long_sentences = len([s for s in content.split('.') if len(s) > 100])
        
        complexity_score = (technical_terms * 0.3 + long_sentences * 0.7) / 10
        return min(complexity_score, 1.0)

    def _assess_actionability(self, content: str) -> float:
        """å®Ÿè¡Œå¯èƒ½æ€§è©•ä¾¡"""
        
        action_words = ["implement", "create", "build", "try", "test", "use", "apply", "practice"]
        action_count = sum(1 for word in action_words if word in content.lower())
        
        return min(action_count / len(action_words), 1.0)

    def _assess_mirralism_relevance(self, content_analysis: Dict) -> float:
        """MIRRALISMé–¢é€£æ€§è©•ä¾¡"""
        
        mirralism_keywords = [
            "personality", "learning", "analysis", "intelligence", "insight",
            "personal", "growth", "development", "system", "platform",
            "automation", "ai", "data", "pattern", "behavior"
        ]
        
        themes = content_analysis.get("themes", [])
        keywords = content_analysis.get("keywords", [])
        
        relevance_count = 0
        for keyword in mirralism_keywords:
            if any(keyword in theme for theme in themes) or keyword in keywords:
                relevance_count += 1
        
        return min(relevance_count / len(mirralism_keywords), 1.0)

    def _get_recent_interests(self, days: int = 30) -> List[Dict]:
        """æœ€è¿‘ã®èˆˆå‘³å±¥æ­´å–å¾—"""
        
        cutoff_date = datetime.now(timezone.utc).timestamp() - (days * 24 * 3600)
        
        return [
            entry for entry in self.interest_history 
            if entry.get("timestamp", 0) > cutoff_date
        ]

    def _calculate_theme_frequency(self, current_themes: List[str], recent_interests: List[Dict]) -> Dict:
        """ãƒ†ãƒ¼ãƒé »åº¦è¨ˆç®—"""
        
        theme_count = {}
        
        for entry in recent_interests:
            for theme in entry.get("themes", []):
                theme_count[theme] = theme_count.get(theme, 0) + 1
        
        current_theme_frequencies = {
            theme: theme_count.get(theme, 0) for theme in current_themes
        }
        
        return {
            "frequencies": current_theme_frequencies,
            "max_frequency": max(current_theme_frequencies.values()) if current_theme_frequencies else 0,
            "total_clips": len(recent_interests)
        }

    def _analyze_interest_trend(self, current_themes: List[str], recent_interests: List[Dict]) -> Dict:
        """èˆˆå‘³ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        
        # ç°¡æ˜“çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        recent_themes = []
        for entry in recent_interests[-10:]:  # æœ€æ–°10ä»¶
            recent_themes.extend(entry.get("themes", []))
        
        trending_up = any(theme in recent_themes[-5:] for theme in current_themes)
        consistent = any(recent_themes.count(theme) >= 3 for theme in current_themes)
        
        return {
            "trending_up": trending_up,
            "consistent": consistent,
            "recent_themes": recent_themes
        }

    def _calculate_novelty(self, current_themes: List[str], recent_interests: List[Dict]) -> float:
        """æ–°è¦æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        
        past_themes = set()
        for entry in recent_interests:
            past_themes.update(entry.get("themes", []))
        
        new_themes = [theme for theme in current_themes if theme not in past_themes]
        
        if not current_themes:
            return 0.0
            
        return len(new_themes) / len(current_themes)

    def _calculate_interest_intensity(self, theme_frequency: Dict) -> float:
        """èˆˆå‘³å¼·åº¦è¨ˆç®—"""
        
        max_freq = theme_frequency.get("max_frequency", 0)
        total_clips = theme_frequency.get("total_clips", 0)
        
        # ã‚¼ãƒ­é™¤ç®—å›é¿
        if total_clips == 0:
            return 0.0
        
        return min(max_freq / total_clips, 1.0)

    def _find_related_clips(self, current_themes: List[str]) -> List[Dict]:
        """é–¢é€£ã‚¯ãƒªãƒƒãƒ—æ¤œç´¢"""
        
        related = []
        
        for entry in self.interest_history:
            entry_themes = entry.get("themes", [])
            if any(theme in entry_themes for theme in current_themes):
                # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ï¼‰
                intersection = len(set(current_themes) & set(entry_themes))
                union = len(set(current_themes) | set(entry_themes))
                similarity = intersection / union if union > 0 else 0.0
                
                related.append({
                    "timestamp": entry.get("timestamp"),
                    "themes": entry_themes,
                    "title": entry.get("title", ""),
                    "similarity": similarity
                })
        
        return sorted(related, key=lambda x: x["similarity"], reverse=True)[:5]

    def _calculate_confidence(self, motivation_estimation: Dict) -> float:
        """ç·åˆä¿¡é ¼åº¦è¨ˆç®—"""
        
        primary = motivation_estimation.get("primary_motivation")
        diversity = motivation_estimation.get("motivation_diversity", 0)
        
        if not primary:
            return 0.3
        
        base_confidence = primary["confidence"]
        diversity_bonus = min(diversity * 0.1, 0.2)
        
        return min(base_confidence + diversity_bonus, 1.0)

    def _update_interest_history(self, interest_analysis: Dict):
        """èˆˆå‘³å±¥æ­´æ›´æ–°"""
        
        new_entry = {
            "timestamp": datetime.now(timezone.utc).timestamp(),
            "themes": interest_analysis["current_themes"],
            "analysis": interest_analysis
        }
        
        self.interest_history.append(new_entry)
        
        # å¤ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’å‰Šé™¤ï¼ˆæœ€æ–°1000ä»¶ã‚’ä¿æŒï¼‰
        if len(self.interest_history) > 1000:
            self.interest_history = self.interest_history[-1000:]
        
        # ä¿å­˜
        self._save_interest_history()

    def _load_motivation_patterns(self) -> Dict:
        """å‹•æ©Ÿãƒ‘ã‚¿ãƒ¼ãƒ³DBèª­ã¿è¾¼ã¿"""
        
        patterns_file = self.project_root / "Data" / "webclip_motivation_patterns.json"
        
        try:
            if patterns_file.exists():
                with open(patterns_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            self.logger.warning(f"å‹•æ©Ÿãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        
        return {}

    def _load_interest_history(self) -> List[Dict]:
        """èˆˆå‘³å±¥æ­´èª­ã¿è¾¼ã¿"""
        
        history_file = self.project_root / "Data" / "webclip_interest_history.json"
        
        try:
            if history_file.exists():
                with open(history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            self.logger.warning(f"èˆˆå‘³å±¥æ­´èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        
        return []

    def _save_interest_history(self):
        """èˆˆå‘³å±¥æ­´ä¿å­˜"""
        
        history_file = self.project_root / "Data" / "webclip_interest_history.json"
        history_file.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(self.interest_history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"èˆˆå‘³å±¥æ­´ä¿å­˜å¤±æ•—: {e}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    analyzer = WebClipMotivationAnalyzer()
    
    # ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
    test_result = analyzer.analyze_clip_motivation(
        article_content="AI-driven personality learning systems are revolutionizing personal development. This comprehensive guide explains how to implement advanced machine learning algorithms for personality analysis and behavioral insights.",
        article_url="https://example.com/ai-personality-learning",
        article_title="Advanced AI Personality Learning: Implementation Guide",
        user_context={"recent_activity": "MIRRALISM development"}
    )
    
    if test_result["success"]:
        analysis = test_result["analysis"]
        print("ğŸ¯ WebClipå‹•æ©Ÿåˆ†æãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 50)
        print(f"è¨˜äº‹: {analysis['article_info']['title']}")
        print(f"èˆˆå‘³æ´å¯Ÿ: {analysis['dialogue']['interest_insight']}")
        print("å‹•æ©Ÿè³ªå•:")
        for q in analysis['dialogue']['motivation_questions']:
            print(f"  - {q}")
        print("æ´»ç”¨ææ¡ˆ:")
        for s in analysis['utilization_suggestions']:
            print(f"  - {s['suggestion']}")
        print(f"ä¿¡é ¼åº¦: {analysis['confidence_score']:.2f}")
    else:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {test_result['error']}")