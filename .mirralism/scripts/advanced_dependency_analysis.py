#!/usr/bin/env python3
"""
MIRRALISM V2 é«˜åº¦ä¾å­˜é–¢ä¿‚åˆ†æã‚·ã‚¹ãƒ†ãƒ 
å¾ªç’°ä¾å­˜ãƒ»æ·±å±¤çš„ä¾å­˜é–¢ä¿‚å•é¡Œã®å¾¹åº•æ¤œå‡º

ä½œæˆæ—¥: 2025å¹´6æœˆ5æ—¥
ç›®çš„: ã‚ˆã‚Šå³å¯†ãªä¾å­˜é–¢ä¿‚æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
"""

import os
import ast
import sys
import json
import logging
import networkx as nx  # ã‚°ãƒ©ãƒ•åˆ†æç”¨
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Set, Tuple, Optional
from collections import defaultdict, deque
import re


class AdvancedDependencyAnalyzer:
    """é«˜åº¦ä¾å­˜é–¢ä¿‚åˆ†æã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_root: str = None):
        if project_root:
            self.project_root = Path(project_root)
        else:
            current_path = Path(__file__).resolve()
            self.project_root = current_path.parent.parent.parent

        self.logger = self._setup_logging()
        self.dependency_graph = nx.DiGraph()
        self.import_patterns = []

        self.logger.info(f"ğŸ”¬ é«˜åº¦ä¾å­˜é–¢ä¿‚åˆ†æã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº† - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {self.project_root}")

    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger("AdvancedDependencyAnalyzer")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def deep_import_analysis(self) -> Dict[str, Any]:
        """æ·±å±¤importåˆ†æ"""
        self.logger.info("ğŸ”¬ æ·±å±¤importåˆ†æé–‹å§‹...")

        analysis_results = {
            "python_files_analyzed": 0,
            "import_statements": [],
            "potential_issues": [],
            "dependency_graph_stats": {},
            "circular_dependencies": [],
            "unused_imports": [],
            "missing_dependencies": [],
        }

        # Python ãƒ•ã‚¡ã‚¤ãƒ«ã®åé›†
        python_files = list(self.project_root.rglob("*.py"))
        excluded_patterns = [
            ".git",
            "__pycache__",
            ".pytest_cache",
            ".mypy_cache",
            ".mirralism/backups",
        ]
        python_files = [
            f
            for f in python_files
            if not any(pattern in str(f) for pattern in excluded_patterns)
        ]

        self.logger.info(f"ğŸ“Š åˆ†æå¯¾è±¡: {len(python_files)} Python ãƒ•ã‚¡ã‚¤ãƒ«")

        for py_file in python_files:
            try:
                analysis_results["python_files_analyzed"] += 1
                file_imports = self._analyze_file_imports(py_file)
                analysis_results["import_statements"].extend(file_imports)

                # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•æ§‹ç¯‰
                self._build_dependency_graph(py_file, file_imports)

            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {py_file} - {e}")

        # å¾ªç’°ä¾å­˜æ¤œå‡º
        analysis_results[
            "circular_dependencies"
        ] = self._detect_circular_dependencies_advanced()

        # æœªä½¿ç”¨importæ¤œå‡º
        analysis_results["unused_imports"] = self._detect_unused_imports()

        # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•çµ±è¨ˆ
        analysis_results["dependency_graph_stats"] = {
            "total_nodes": self.dependency_graph.number_of_nodes(),
            "total_edges": self.dependency_graph.number_of_edges(),
            "strongly_connected_components": len(
                list(nx.strongly_connected_components(self.dependency_graph))
            ),
            "longest_path": self._find_longest_dependency_path(),
        }

        self.logger.info(f"ğŸ”¬ æ·±å±¤åˆ†æå®Œäº†")
        return analysis_results

    def _analyze_file_imports(self, file_path: Path) -> List[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®importæ–‡ã‚’è©³ç´°åˆ†æ"""
        imports = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # ASTè§£æ
            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(
                            {
                                "file": str(file_path.relative_to(self.project_root)),
                                "line": node.lineno,
                                "type": "import",
                                "module": alias.name,
                                "alias": alias.asname,
                                "level": 0,
                                "is_local": self._is_local_module(alias.name),
                                "raw_code": f"import {alias.name}",
                            }
                        )

                elif isinstance(node, ast.ImportFrom):
                    module_name = node.module or ""
                    for alias in node.names:
                        imports.append(
                            {
                                "file": str(file_path.relative_to(self.project_root)),
                                "line": node.lineno,
                                "type": "from_import",
                                "module": module_name,
                                "name": alias.name,
                                "alias": alias.asname,
                                "level": node.level,
                                "is_local": self._is_local_module(module_name),
                                "raw_code": f"from {module_name} import {alias.name}",
                            }
                        )

        except SyntaxError as e:
            self.logger.warning(f"âš ï¸ æ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {file_path}:{e.lineno} - {e.msg}")
        except Exception as e:
            self.logger.error(f"âŒ importåˆ†æã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

        return imports

    def _is_local_module(self, module_name: str) -> bool:
        """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã©ã†ã‹ã®åˆ¤å®š"""
        if not module_name:
            return False

        # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ»å¤–éƒ¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®é™¤å¤–
        external_packages = {
            "numpy",
            "pandas",
            "sklearn",
            "requests",
            "json",
            "os",
            "sys",
            "datetime",
            "pathlib",
            "typing",
            "collections",
            "itertools",
            "sqlite3",
            "logging",
            "subprocess",
            "hashlib",
            "shutil",
            "openai",
            "anthropic",
            "sqlalchemy",
            "httpx",
            "pyyaml",
            "python-dotenv",
            "black",
            "flake8",
            "isort",
            "mypy",
            "bandit",
            "pre-commit",
            "pytest",
            "cryptography",
            "rich",
            "colorama",
            "tqdm",
            "click",
            "python-dateutil",
            "joblib",
        }

        base_module = module_name.split(".")[0]

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆ¤å®š
        project_modules = {
            "Core",
            "API",
            "Prototype",
            "Interface",
            "Data",
            "MyBrain",
            "scripts",
        }

        return (
            base_module in project_modules
            or base_module not in external_packages
            and not base_module.startswith("_")
        )

    def _build_dependency_graph(self, file_path: Path, imports: List[Dict[str, Any]]):
        """ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰"""
        file_node = str(file_path.relative_to(self.project_root))

        if not self.dependency_graph.has_node(file_node):
            self.dependency_graph.add_node(file_node)

        for imp in imports:
            if imp["is_local"]:
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å ´åˆã€å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                target_files = self._resolve_module_to_files(imp["module"])

                for target_file in target_files:
                    if target_file != file_node:  # è‡ªå·±å‚ç…§é™¤å¤–
                        self.dependency_graph.add_edge(
                            file_node, target_file, import_info=imp
                        )

    def _resolve_module_to_files(self, module_name: str) -> List[str]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¸ã®è§£æ±º"""
        files = []

        # ãƒ‰ãƒƒãƒˆè¨˜æ³•ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«å¤‰æ›
        path_parts = module_name.split(".")

        # å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        potential_paths = [
            "/".join(path_parts) + ".py",
            "/".join(path_parts) + "/__init__.py",
        ]

        for potential_path in potential_paths:
            full_path = self.project_root / potential_path
            if full_path.exists():
                files.append(str(Path(potential_path)))

        return files

    def _detect_circular_dependencies_advanced(self) -> List[Dict[str, Any]]:
        """é«˜åº¦ãªå¾ªç’°ä¾å­˜æ¤œå‡º"""
        circular_deps = []

        try:
            # å¼·é€£çµæˆåˆ†ã®æ¤œå‡º
            strongly_connected = list(
                nx.strongly_connected_components(self.dependency_graph)
            )

            for component in strongly_connected:
                if len(component) > 1:  # è¤‡æ•°ãƒãƒ¼ãƒ‰ã®å¾ªç’°
                    # æœ€çŸ­å¾ªç’°ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹
                    component_list = list(component)
                    subgraph = self.dependency_graph.subgraph(component)

                    # å¾ªç’°ã®è©³ç´°åˆ†æ
                    try:
                        cycle = nx.find_cycle(subgraph)
                        cycle_info = {
                            "type": "circular_dependency",
                            "files_involved": component_list,
                            "cycle_length": len(cycle),
                            "cycle_path": [edge[0] for edge in cycle] + [cycle[-1][1]],
                            "severity": "high" if len(component) > 3 else "medium",
                            "description": f"å¾ªç’°ä¾å­˜æ¤œå‡º: {len(component)}ãƒ•ã‚¡ã‚¤ãƒ«é–“",
                        }
                        circular_deps.append(cycle_info)

                    except nx.NetworkXNoCycle:
                        # è‡ªå·±å¾ªç’°ã®å ´åˆ
                        for node in component:
                            if self.dependency_graph.has_edge(node, node):
                                circular_deps.append(
                                    {
                                        "type": "self_dependency",
                                        "file": node,
                                        "severity": "low",
                                        "description": f"è‡ªå·±å‚ç…§: {node}",
                                    }
                                )

        except Exception as e:
            self.logger.error(f"âŒ å¾ªç’°ä¾å­˜æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")

        return circular_deps

    def _detect_unused_imports(self) -> List[Dict[str, Any]]:
        """æœªä½¿ç”¨importæ¤œå‡º"""
        unused_imports = []

        # ç°¡æ˜“å®Ÿè£…: ã‚ˆã‚Šè©³ç´°ãªè§£æã¯åˆ¥é€”å®Ÿè£…å¯èƒ½
        for py_file in self.project_root.rglob("*.py"):
            if any(
                excluded in str(py_file)
                for excluded in [".git", "__pycache__", ".mirralism/backups"]
            ):
                continue

            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()

                # ASTè§£æã§importæ–‡ã¨ä½¿ç”¨ç®‡æ‰€ã‚’ãƒã‚§ãƒƒã‚¯
                tree = ast.parse(content)
                imports_in_file = []
                names_used = set()

                # importæ–‡ã®åé›†
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports_in_file.append(
                                {
                                    "name": alias.asname or alias.name.split(".")[0],
                                    "full_name": alias.name,
                                    "line": node.lineno,
                                    "type": "import",
                                }
                            )
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            for alias in node.names:
                                imports_in_file.append(
                                    {
                                        "name": alias.asname or alias.name,
                                        "full_name": f"{node.module}.{alias.name}",
                                        "line": node.lineno,
                                        "type": "from_import",
                                    }
                                )

                # ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹åå‰ã®åé›†
                for node in ast.walk(tree):
                    if isinstance(node, ast.Name):
                        names_used.add(node.id)

                # æœªä½¿ç”¨importæ¤œå‡º
                for imp in imports_in_file:
                    if imp["name"] not in names_used and imp["name"] != "__future__":
                        unused_imports.append(
                            {
                                "file": str(py_file.relative_to(self.project_root)),
                                "line": imp["line"],
                                "import_name": imp["name"],
                                "full_import": imp["full_name"],
                                "type": imp["type"],
                                "severity": "low",
                                "description": f"æœªä½¿ç”¨import: {imp['name']}",
                            }
                        )

            except Exception as e:
                self.logger.error(f"âŒ æœªä½¿ç”¨importæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {py_file} - {e}")

        return unused_imports

    def _find_longest_dependency_path(self) -> int:
        """æœ€é•·ä¾å­˜ãƒ‘ã‚¹ã®æ¤œå‡º"""
        try:
            if nx.is_directed_acyclic_graph(self.dependency_graph):
                return nx.dag_longest_path_length(self.dependency_graph)
            else:
                return -1  # å¾ªç’°ãŒã‚ã‚‹ãŸã‚æ¸¬å®šä¸å¯
        except:
            return 0

    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        self.logger.info("ğŸ“‹ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")

        analysis_results = self.deep_import_analysis()

        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        summary = {
            "analysis_timestamp": datetime.now().isoformat(),
            "total_python_files": analysis_results["python_files_analyzed"],
            "total_imports": len(analysis_results["import_statements"]),
            "local_imports": len(
                [
                    imp
                    for imp in analysis_results["import_statements"]
                    if imp["is_local"]
                ]
            ),
            "external_imports": len(
                [
                    imp
                    for imp in analysis_results["import_statements"]
                    if not imp["is_local"]
                ]
            ),
            "circular_dependencies_count": len(
                analysis_results["circular_dependencies"]
            ),
            "unused_imports_count": len(analysis_results["unused_imports"]),
            "dependency_complexity": analysis_results["dependency_graph_stats"],
            "overall_health_score": self._calculate_health_score(analysis_results),
        }

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
        full_report = {
            "summary": summary,
            "detailed_analysis": analysis_results,
            "recommendations": self._generate_recommendations(analysis_results),
        }

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = (
            self.project_root
            / ".mirralism"
            / "reports"
            / f"advanced_dependency_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        report_file.parent.mkdir(parents=True, exist_ok=True)

        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(full_report, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {report_file}")
        return full_report

    def _calculate_health_score(self, analysis_results: Dict[str, Any]) -> float:
        """ä¾å­˜é–¢ä¿‚å¥å…¨æ€§ã‚¹ã‚³ã‚¢è¨ˆç®— (0-100)"""
        score = 100.0

        # å¾ªç’°ä¾å­˜ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        circular_penalty = len(analysis_results["circular_dependencies"]) * 10
        score -= min(circular_penalty, 30)

        # æœªä½¿ç”¨importã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        unused_penalty = len(analysis_results["unused_imports"]) * 0.5
        score -= min(unused_penalty, 10)

        # è¤‡é›‘åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£
        graph_stats = analysis_results["dependency_graph_stats"]
        if graph_stats["total_nodes"] > 0:
            complexity_ratio = graph_stats["total_edges"] / graph_stats["total_nodes"]
            if complexity_ratio > 3:  # å¹³å‡ã—ã¦å„ãƒ•ã‚¡ã‚¤ãƒ«ãŒ3ã¤ä»¥ä¸Šã®ä¾å­˜é–¢ä¿‚
                score -= (complexity_ratio - 3) * 5

        return max(0.0, min(100.0, score))

    def _generate_recommendations(self, analysis_results: Dict[str, Any]) -> List[str]:
        """æ”¹å–„ææ¡ˆã®ç”Ÿæˆ"""
        recommendations = []

        if analysis_results["circular_dependencies"]:
            recommendations.append("ğŸ”„ å¾ªç’°ä¾å­˜ã‚’è§£æ¶ˆã—ã¦ãã ã•ã„ã€‚ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚„æŠ½è±¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å°å…¥ã‚’æ¤œè¨ã€‚")

        if analysis_results["unused_imports"]:
            recommendations.append("ğŸ§¹ æœªä½¿ç”¨importã‚’å‰Šé™¤ã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã«ä¿ã£ã¦ãã ã•ã„ã€‚")

        graph_stats = analysis_results["dependency_graph_stats"]
        if graph_stats["total_nodes"] > 0:
            complexity_ratio = graph_stats["total_edges"] / graph_stats["total_nodes"]
            if complexity_ratio > 4:
                recommendations.append("ğŸ“Š ä¾å­˜é–¢ä¿‚ãŒè¤‡é›‘ã§ã™ã€‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ã‚„ä¾å­˜æ³¨å…¥ã®æ¤œè¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")

        if graph_stats["longest_path"] > 10:
            recommendations.append("ğŸ“ ä¾å­˜ãƒã‚§ãƒ¼ãƒ³ãŒé•·ã™ãã¾ã™ã€‚ã‚ˆã‚Šå¹³å¦ãªæ§‹é€ ã¸ã®å†è¨­è¨ˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")

        if not recommendations:
            recommendations.append("âœ… ä¾å­˜é–¢ä¿‚ã¯å¥å…¨ãªçŠ¶æ…‹ã§ã™ã€‚ç¾åœ¨ã®æ§‹é€ ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚")

        return recommendations


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    analyzer = AdvancedDependencyAnalyzer()
    report = analyzer.generate_comprehensive_report()

    # çµæœè¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ”¬ MIRRALISM V2 é«˜åº¦ä¾å­˜é–¢ä¿‚åˆ†æçµæœ")
    print("=" * 80)

    summary = report["summary"]
    print(f"ğŸ“Š åˆ†æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {summary['total_python_files']}")
    print(f"ğŸ“‹ ç·importæ•°: {summary['total_imports']}")
    print(f"ğŸ  ãƒ­ãƒ¼ã‚«ãƒ«import: {summary['local_imports']}")
    print(f"ğŸ“¦ å¤–éƒ¨import: {summary['external_imports']}")
    print(f"ğŸ”„ å¾ªç’°ä¾å­˜: {summary['circular_dependencies_count']}ä»¶")
    print(f"ğŸ§¹ æœªä½¿ç”¨import: {summary['unused_imports_count']}ä»¶")
    print(f"ğŸ’¯ å¥å…¨æ€§ã‚¹ã‚³ã‚¢: {summary['overall_health_score']:.1f}/100")

    complexity = summary["dependency_complexity"]
    print(f"\nğŸ“ˆ ä¾å­˜é–¢ä¿‚è¤‡é›‘åº¦:")
    print(f"  - ãƒãƒ¼ãƒ‰æ•°: {complexity['total_nodes']}")
    print(f"  - ã‚¨ãƒƒã‚¸æ•°: {complexity['total_edges']}")
    print(f"  - æœ€é•·ãƒ‘ã‚¹: {complexity['longest_path']}")

    print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
    for rec in report["recommendations"]:
        print(f"  {rec}")

    if summary["circular_dependencies_count"] > 0:
        print("\nğŸ”„ å¾ªç’°ä¾å­˜è©³ç´°:")
        for circ in report["detailed_analysis"]["circular_dependencies"][:3]:
            print(f"  - {circ['description']}")
            print(f"    é–¢ä¸ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(circ.get('files_involved', [])[:3])}")

    print("=" * 80)


if __name__ == "__main__":
    main()
