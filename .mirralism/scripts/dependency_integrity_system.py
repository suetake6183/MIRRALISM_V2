#!/usr/bin/env python3
"""
MIRRALISM V2 ä¾å­˜é–¢ä¿‚æ•´åˆæ€§ã‚·ã‚¹ãƒ†ãƒ 
V1â†’V2ç¶™æ‰¿ã«ã‚ˆã‚‹ä¾å­˜é–¢ä¿‚ç ´ç¶»ã®å®Œå…¨æ¤œå‡ºãƒ»ä¿®æ­£

ä½œæˆæ—¥: 2025å¹´6æœˆ5æ—¥
ç›®çš„: ä¾å­˜é–¢ä¿‚æ•´åˆæ€§ã®å¾¹åº•çš„ãƒã‚§ãƒƒã‚¯ãƒ»è‡ªå‹•ä¿®æ­£ãƒ»ç¶™ç¶šç›£è¦–
é‡è¦åº¦: Critical - å“è³ªä¿è¨¼ã®æ ¹å¹¹
"""

import ast
import hashlib
import json
import logging
import os
import re
import shutil
import sqlite3
import subprocess
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any
from typing import Dict
from typing import List
from typing import Optional
from typing import Set
from typing import Tuple


@dataclass
class DependencyIssue:
    """ä¾å­˜é–¢ä¿‚å•é¡Œã®è©³ç´°æƒ…å ±"""

    file_path: str
    line_number: int
    issue_type: str  # 'missing_import', 'circular_dependency', 'version_conflict', 'broken_path'
    description: str
    severity: str  # 'critical', 'high', 'medium', 'low'
    suggested_fix: str
    code_context: str


class DependencyIntegritySystem:
    """
    ä¾å­˜é–¢ä¿‚æ•´åˆæ€§ã‚·ã‚¹ãƒ†ãƒ 

    æ©Ÿèƒ½:
    1. Python/JavaScript/TypeScript import ã®å®Œå…¨æ€§æ¤œè¨¼
    2. å¾ªç’°ä¾å­˜ã®æ¤œå‡ºãƒ»è§£æ±º
    3. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    4. V1â†’V2ãƒ‘ã‚¹å¤‰æ›´ã«ã‚ˆã‚‹ç ´ç¶»æ¤œå‡º
    5. è‡ªå‹•ä¿®æ­£ãƒ»ç¶™ç¶šç›£è¦–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
    """

    def __init__(self, project_root: str = None):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        if project_root:
            self.project_root = Path(project_root)
        else:
            current_path = Path(__file__).resolve()
            self.project_root = current_path.parent.parent.parent

        self.logger = self._setup_logging()

        # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
        self.target_extensions = {
            "python": [".py"],
            "javascript": [".js", ".jsx", ".ts", ".tsx"],
            "config": [".json", ".yaml", ".yml", ".toml", ".cfg", ".ini"],
        }

        # V1â†’V2ãƒ‘ã‚¹ç§»è¡Œãƒãƒƒãƒ”ãƒ³ã‚°
        self.path_migrations = {
            "MyBrain.MIRRALISM.Core.": "Core.",
            "MyBrain.MIRRALISM.API.": "API.",
            "MyBrain.MIRRALISM.Prototype.": "Prototype.",
            "MyBrain.MIRRALISM.": "",
            "MyBrain.Core.": "Core.",
            "MyBrain.API.": "API.",
            "from MyBrain.MIRRALISM.Core": "from Core",
            "from MyBrain.MIRRALISM.API": "from API",
            "from MyBrain.MIRRALISM": "from .",
            "from MyBrain.Core": "from Core",
            "import MyBrain.MIRRALISM.Core": "import Core",
            "import MyBrain.MIRRALISM": "import .",
        }

        # åˆ†æçµæœãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.integrity_db_path = (
            self.project_root / ".mirralism" / "dependency_integrity.db"
        )
        self.integrity_db_path.parent.mkdir(parents=True, exist_ok=True)

        # ä¿®æ­£å±¥æ­´ãƒ­ã‚°
        self.fix_log_path = (
            self.project_root / ".mirralism" / "logs" / "dependency_fixes.log"
        )
        self.fix_log_path.parent.mkdir(parents=True, exist_ok=True)

        self.logger.info(f"ğŸ” ä¾å­˜é–¢ä¿‚æ•´åˆæ€§ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº† - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {self.project_root}")

    def _setup_logging(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger("DependencyIntegrity")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def scan_all_files(self) -> Dict[str, List[Path]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³"""
        self.logger.info("ğŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹...")

        scanned_files = {"python": [], "javascript": [], "config": []}

        # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        excluded_dirs = {
            ".git",
            "__pycache__",
            ".pytest_cache",
            ".mypy_cache",
            "node_modules",
            ".vscode",
            ".cursor",
            ".DS_Store",
            ".mirralism/backups",  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯é™¤å¤–
        }

        for file_path in self.project_root.rglob("*"):
            if file_path.is_file():
                # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒã‚§ãƒƒã‚¯
                if any(excluded in str(file_path) for excluded in excluded_dirs):
                    continue

                # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ¤å®š
                for file_type, extensions in self.target_extensions.items():
                    if file_path.suffix in extensions:
                        scanned_files[file_type].append(file_path)
                        break

        total_files = sum(len(files) for files in scanned_files.values())
        self.logger.info(f"ğŸ“Š ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {total_files}ãƒ•ã‚¡ã‚¤ãƒ«")
        for file_type, files in scanned_files.items():
            self.logger.info(f"  - {file_type}: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«")

        return scanned_files

    def analyze_python_imports(self, python_files: List[Path]) -> List[DependencyIssue]:
        """Python import ã®å®Œå…¨æ€§åˆ†æ"""
        self.logger.info("ğŸ Python import åˆ†æé–‹å§‹...")

        issues = []

        for file_path in python_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

                # importæ–‡ã®è¡Œã”ã¨è§£æ
                lines = content.split("\n")
                for line_no, line in enumerate(lines, 1):
                    line_stripped = line.strip()

                    # importæ–‡ã®ãƒã‚§ãƒƒã‚¯
                    if (
                        line_stripped.startswith("import ")
                        or line_stripped.startswith("from ")
                    ) and not line_stripped.startswith("#"):
                        # V1â†’V2ãƒ‘ã‚¹å¤‰æ›´ã«ã‚ˆã‚‹ç ´ç¶»ãƒã‚§ãƒƒã‚¯
                        for old_pattern, new_pattern in self.path_migrations.items():
                            if old_pattern in line:
                                issues.append(
                                    DependencyIssue(
                                        file_path=str(
                                            file_path.relative_to(self.project_root)
                                        ),
                                        line_number=line_no,
                                        issue_type="broken_path",
                                        description=f"V1ãƒ‘ã‚¹å‚ç…§: {old_pattern}",
                                        severity="high",
                                        suggested_fix=f"ãƒ‘ã‚¹ã‚’æ›´æ–°: {line.replace(old_pattern, new_pattern)}",
                                        code_context=line.strip(),
                                    )
                                )

            except Exception as e:
                self.logger.error(f"âŒ Pythonåˆ†æã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

        self.logger.info(f"ğŸ Pythonåˆ†æå®Œäº†: {len(issues)}ä»¶ã®å•é¡Œæ¤œå‡º")
        return issues

    def analyze_package_dependencies(self) -> List[DependencyIssue]:
        """ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¾å­˜é–¢ä¿‚ã®æ•´åˆæ€§åˆ†æ"""
        self.logger.info("ğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¾å­˜é–¢ä¿‚åˆ†æé–‹å§‹...")

        issues = []

        # requirements.txt ã®åˆ†æ
        req_files = [
            self.project_root / "requirements.txt",
            self.project_root / "MyBrain" / "requirements.txt",
        ]

        packages_by_file = {}

        for req_file in req_files:
            if req_file.exists():
                with open(req_file, "r") as f:
                    lines = f.readlines()
                    packages = {}

                    for line_no, line in enumerate(lines, 1):
                        line_stripped = line.strip()
                        if "==" in line_stripped and not line_stripped.startswith("#"):
                            try:
                                package_name, version = line_stripped.split("==", 1)
                                packages[package_name.strip()] = version.strip()
                            except ValueError:
                                issues.append(
                                    DependencyIssue(
                                        file_path=str(
                                            req_file.relative_to(self.project_root)
                                        ),
                                        line_number=line_no,
                                        issue_type="malformed_dependency",
                                        description=f"ä¸æ­£ãªä¾å­˜é–¢ä¿‚è¨˜è¿°: {line_stripped}",
                                        severity="medium",
                                        suggested_fix="æ­£ã—ã„å½¢å¼: package==version",
                                        code_context=line.strip(),
                                    )
                                )

                    packages_by_file[str(req_file)] = packages

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç«¶åˆãƒã‚§ãƒƒã‚¯
        all_packages = {}
        for file_path, packages in packages_by_file.items():
            for package_name, version in packages.items():
                if package_name in all_packages:
                    if all_packages[package_name] != version:
                        issues.append(
                            DependencyIssue(
                                file_path=Path(file_path)
                                .relative_to(self.project_root)
                                .as_posix(),
                                line_number=0,
                                issue_type="version_conflict",
                                description=f"ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç«¶åˆ: {package_name} ({all_packages[package_name]} vs {version})",
                                severity="high",
                                suggested_fix=f"ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’çµ±ä¸€: {package_name}=={version}",
                                code_context=f"{package_name}=={version}",
                            )
                        )
                else:
                    all_packages[package_name] = version

        self.logger.info(f"ğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åˆ†æå®Œäº†: {len(issues)}ä»¶ã®å•é¡Œæ¤œå‡º")
        return issues

    def execute_automated_fixes(self, issues: List[DependencyIssue]) -> Dict[str, Any]:
        """è‡ªå‹•ä¿®æ­£ã®å®Ÿè¡Œ"""
        self.logger.info("ğŸ”§ è‡ªå‹•ä¿®æ­£å®Ÿè¡Œé–‹å§‹...")

        fix_results = {
            "fixed_issues": [],
            "failed_fixes": [],
            "backup_created": False,
            "backup_path": "",
            "fix_timestamp": datetime.now().isoformat(),
        }

        # ä¿®æ­£å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_dir = self._create_backup_before_fixes()
        fix_results["backup_created"] = True
        fix_results["backup_path"] = str(backup_dir)

        for issue in issues:
            if issue.issue_type == "broken_path":
                try:
                    file_path = self.project_root / issue.file_path
                    if file_path.exists():
                        with open(file_path, "r", encoding="utf-8") as f:
                            content = f.read()

                        # V1â†’V2ãƒ‘ã‚¹å¤‰æ›´ã®è‡ªå‹•ä¿®æ­£
                        original_content = content
                        for old_pattern, new_pattern in self.path_migrations.items():
                            content = content.replace(old_pattern, new_pattern)

                        if content != original_content:
                            with open(file_path, "w", encoding="utf-8") as f:
                                f.write(content)

                            fix_results["fixed_issues"].append(
                                {
                                    "issue": issue.__dict__,
                                    "fix_applied": "path_migration",
                                    "timestamp": datetime.now().isoformat(),
                                }
                            )

                except Exception as e:
                    fix_results["failed_fixes"].append(
                        {
                            "issue": issue.__dict__,
                            "error": str(e),
                            "timestamp": datetime.now().isoformat(),
                        }
                    )

        self.logger.info(
            f"ğŸ”§ è‡ªå‹•ä¿®æ­£å®Œäº†: {len(fix_results['fixed_issues'])}ä»¶ä¿®æ­£, {len(fix_results['failed_fixes'])}ä»¶å¤±æ•—"
        )
        return fix_results

    def _create_backup_before_fixes(self) -> Path:
        """ä¿®æ­£å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        backup_dir = (
            self.project_root
            / ".mirralism"
            / "backups"
            / f"dependency_fixes_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        backup_dir.mkdir(parents=True, exist_ok=True)

        # ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        important_files = [
            "requirements.txt",
            "package.json",
            "MyBrain/requirements.txt",
        ]

        for file_rel_path in important_files:
            file_path = self.project_root / file_rel_path
            if file_path.exists():
                backup_file_path = backup_dir / file_rel_path
                backup_file_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, backup_file_path)

        return backup_dir

    def execute_complete_analysis(self) -> Dict[str, Any]:
        """å®Œå…¨ãªä¾å­˜é–¢ä¿‚åˆ†æã®å®Ÿè¡Œ"""
        self.logger.info("ğŸ” å®Œå…¨ä¾å­˜é–¢ä¿‚åˆ†æå®Ÿè¡Œé–‹å§‹...")

        start_time = datetime.now()

        # 1. å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³
        scanned_files = self.scan_all_files()

        # 2. Python import åˆ†æ
        python_issues = self.analyze_python_imports(scanned_files["python"])

        # 3. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¾å­˜é–¢ä¿‚åˆ†æ
        package_issues = self.analyze_package_dependencies()

        # 4. å…¨å•é¡Œã®çµ±åˆ
        all_issues = python_issues + package_issues

        # 5. è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ
        automated_fix_results = self.execute_automated_fixes(
            [
                issue
                for issue in all_issues
                if issue.issue_type in ["broken_path", "version_conflict"]
            ]
        )

        # 6. çµæœä¿å­˜
        analysis_results = {
            "analysis_timestamp": start_time.isoformat(),
            "analysis_duration": (datetime.now() - start_time).total_seconds(),
            "scanned_files_summary": {k: len(v) for k, v in scanned_files.items()},
            "issues_detected": len(all_issues),
            "automated_fixes": automated_fix_results,
            "all_issues": [issue.__dict__ for issue in all_issues],
        }

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        results_file = (
            self.project_root
            / ".mirralism"
            / "reports"
            / f"dependency_analysis_{start_time.strftime('%Y%m%d_%H%M%S')}.json"
        )
        results_file.parent.mkdir(parents=True, exist_ok=True)

        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(analysis_results, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ğŸ” å®Œå…¨åˆ†æå®Œäº†: {len(all_issues)}ä»¶ã®å•é¡Œæ¤œå‡º")
        self.logger.info(f"ğŸ“Š çµæœä¿å­˜: {results_file}")

        return analysis_results


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="MIRRALISM V2 ä¾å­˜é–¢ä¿‚æ•´åˆæ€§ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--project-root", help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹")
    parser.add_argument("--quick-check", action="store_true", help="é«˜é€Ÿãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--pre-commit", action="store_true", help="Pre-commit hook ãƒ¢ãƒ¼ãƒ‰")

    args = parser.parse_args()

    system = DependencyIntegritySystem(args.project_root)

    if args.quick_check or args.pre_commit:
        # é«˜é€Ÿãƒã‚§ãƒƒã‚¯ï¼ˆä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
        scanned_files = system.scan_all_files()
        issues = system.analyze_python_imports(
            scanned_files["python"][:10]
        )  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿

        if issues:
            print(f"âŒ {len(issues)}ä»¶ã®ä¾å­˜é–¢ä¿‚å•é¡Œæ¤œå‡º")
            for issue in issues[:3]:  # æœ€åˆã®3ä»¶ã®ã¿è¡¨ç¤º
                print(f"  - {issue.file_path}:{issue.line_number} {issue.description}")
            sys.exit(1)
        else:
            print("âœ… ä¾å­˜é–¢ä¿‚æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯æˆåŠŸ")
            sys.exit(0)
    else:
        # å®Œå…¨åˆ†æ
        results = system.execute_complete_analysis()

        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "=" * 60)
        print("ğŸ” MIRRALISM V2 ä¾å­˜é–¢ä¿‚æ•´åˆæ€§åˆ†æçµæœ")
        print("=" * 60)
        print(f"ğŸ“Š åˆ†ææ™‚é–“: {results['analysis_duration']:.2f}ç§’")
        print(f"ğŸ“‚ ã‚¹ã‚­ãƒ£ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«: {sum(results['scanned_files_summary'].values())}ä»¶")
        print(f"âš ï¸  æ¤œå‡ºå•é¡Œ: {results['issues_detected']}ä»¶")

        if results["automated_fixes"]["fixed_issues"]:
            print(f"ğŸ”§ è‡ªå‹•ä¿®æ­£: {len(results['automated_fixes']['fixed_issues'])}ä»¶")

        if results["issues_detected"] > 0:
            print("\nğŸ“‹ ä¸»è¦å•é¡Œ:")
            for issue_dict in results["all_issues"][:5]:  # æœ€åˆã®5ä»¶
                print(f"  - {issue_dict['file_path']}:{issue_dict['line_number']}")
                print(f"    {issue_dict['description']}")
                print(f"    ä¿®æ­£ææ¡ˆ: {issue_dict['suggested_fix']}")

            print("=" * 60)


if __name__ == "__main__":
    main()
