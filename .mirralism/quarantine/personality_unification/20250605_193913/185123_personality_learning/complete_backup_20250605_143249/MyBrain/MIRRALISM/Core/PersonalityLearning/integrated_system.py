#!/usr/bin/env python3
"""
MIRRALISM PersonalityLearning çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
=======================================

V2ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ + PersonalityLearningCore ã®å®Œå…¨çµ±åˆ
53% â†’ 95% ç²¾åº¦é€²åŒ–ã®å®Ÿç¾

çµ±åˆå¯¾è±¡:
- database.py (V2ã‚¹ã‚­ãƒ¼ãƒ)
- personality_learning_core.py (V1äº’æ›æ€§ä¿æŒ)
- TaskMasteré€£æº
- SuperWhisperçµ±åˆ

ä½œæˆè€…: MIRRALISM V2 çµ±åˆãƒãƒ¼ãƒ 
ä½œæˆæ—¥: 2025å¹´6æœˆ3æ—¥
"""

import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any
from typing import Dict
from typing import Optional

# ãƒ‘ã‚¹è¨­å®šï¼ˆåŒä¸€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    from database import PersonalityLearningDatabase
    from personality_learning_core import PersonalityLearningCore
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿
    import importlib.util

    # database.py
    db_spec = importlib.util.spec_from_file_location(
        "database", current_dir / "database.py"
    )
    db_module = importlib.util.module_from_spec(db_spec)
    db_spec.loader.exec_module(db_module)
    PersonalityLearningDatabase = db_module.PersonalityLearningDatabase

    # personality_learning_core.py
    core_spec = importlib.util.spec_from_file_location(
        "personality_learning_core",
        current_dir / "personality_learning_core.py",
    )
    core_module = importlib.util.module_from_spec(core_spec)
    core_spec.loader.exec_module(core_module)
    PersonalityLearningCore = core_module.PersonalityLearningCore

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MirralismPersonalityLearning:
    """
    MIRRALISM PersonalityLearning å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ 

    æ©Ÿèƒ½çµ±åˆ:
    - V2ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (10ãƒ†ãƒ¼ãƒ–ãƒ« + 18ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
    - PersonalityLearningCore (V1äº’æ›æ€§)
    - TaskMasteré€£æº (å­¦ç¿’åŠ¹æœç›¸é–¢)
    - SuperWhisperçµ±åˆ (éŸ³å£°ãƒ‡ãƒ¼ã‚¿1.5å€é‡ã¿ä»˜ã‘)

    é€²åŒ–ç›®æ¨™: 53% â†’ 95% ç²¾åº¦å®Ÿç¾
    """

    def __init__(self, db_path: Optional[str] = None):
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""

        # ãƒ‘ã‚¹è¨­å®š
        if db_path is None:
            current_dir = Path(__file__).parent
            db_path = str(current_dir / "personality_learning_v2.db")

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.database = PersonalityLearningDatabase(db_path)
        self.core = PersonalityLearningCore(db_path)

        # çµ±åˆã‚·ã‚¹ãƒ†ãƒ è¨­å®š
        self.version = "2.0_MIRRALISM_INTEGRATED"
        self.target_accuracy = 95.0
        self.current_accuracy = self.core.get_learned_accuracy()

        # é€²åŒ–æ®µéšå®šç¾©
        self.evolution_stages = {
            53.0: "V1_baseline",
            61.0: "V1_learned",
            70.0: "V2_training",
            80.0: "V2_validation",
            90.0: "V2_production_ready",
            95.0: "V2_target_achieved",
        }

        logger.info(f"MIRRALISMçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº† - ç¾åœ¨ç²¾åº¦: {self.current_accuracy}%")

    def analyze_entry(
        self,
        content: str,
        source_type: str = "journal",
        voice_data: Optional[Dict] = None,
        task_context: Optional[Dict] = None,
    ) -> Dict[str, Any]:
        """
        çµ±åˆåˆ†æã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

        Args:
            content: åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            source_type: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ ("journal", "voice", "task", "interaction")
            voice_data: SuperWhisperéŸ³å£°ãƒ‡ãƒ¼ã‚¿ (optional)
            task_context: TaskMasteré€£æºãƒ‡ãƒ¼ã‚¿ (optional)

        Returns:
            Dict: çµ±åˆåˆ†æçµæœ + ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²
        """
        analysis_id = f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        start_time = datetime.now()

        try:
            # Coreåˆ†æå®Ÿè¡Œ
            if source_type == "voice" and voice_data:
                # SuperWhisperçµ±åˆåˆ†æ
                # process_voice_input expects the voice metadata and the
                # transcribed content in a single dictionary. Previously only
                # ``{"content": content, "metadata": voice_data}`` was passed
                # which resulted in quality and confidence information being
                # ignored.  Merge the parameters correctly so that voice
                # related scores are taken into account.
                core_voice_data = {"content": content, **voice_data}
                core_result = self.core.process_voice_input(core_voice_data)
            else:
                # æ¨™æº–åˆ†æ
                core_result = self.core.analyze_journal_entry(
                    content, source_type, task_context
                )

            if not core_result["success"]:
                return core_result

            # åˆ†æãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            enhanced_analysis = self._enhance_analysis(
                core_result, source_type, voice_data, task_context
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²
            self._record_to_database(enhanced_analysis, analysis_id, start_time)

            # ç²¾åº¦é€²åŒ–ãƒã‚§ãƒƒã‚¯
            evolution_update = self._check_evolution_progress(enhanced_analysis)

            # æœ€çµ‚çµæœçµ±åˆ
            final_result = {
                **enhanced_analysis,
                "analysis_id": analysis_id,
                "database_recorded": True,
                "evolution_status": evolution_update,
                "processing_time_total": (datetime.now() - start_time).total_seconds(),
            }

            logger.info(
                f"çµ±åˆåˆ†æå®Œäº†: {analysis_id}, ç²¾åº¦: {enhanced_analysis['analysis']['suetake_likeness_index']}%"
            )

            return final_result

        except Exception as e:
            logger.error(f"çµ±åˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": f"çµ±åˆåˆ†æå¤±æ•—: {str(e)}",
                "analysis_id": analysis_id,
                "timestamp": datetime.now().isoformat(),
            }

    def _enhance_analysis(
        self,
        core_result: Dict,
        source_type: str,
        voice_data: Optional[Dict] = None,
        task_context: Optional[Dict] = None,
    ) -> Dict[str, Any]:
        """åˆ†æçµæœã®æ‹¡å¼µï¼ˆçµ±åˆæ©Ÿèƒ½è¿½åŠ ï¼‰"""

        enhanced = core_result.copy()
        analysis = enhanced["analysis"]

        # V2çµ±åˆæ‹¡å¼µ
        analysis["mirralism_integration"] = {
            "database_version": "v2",
            "integration_level": "full",
            "source_type": source_type,
            "accuracy_evolution_stage": self._get_evolution_stage(
                analysis["suetake_likeness_index"]
            ),
        }

        # SuperWhisperçµ±åˆæƒ…å ±
        if source_type == "voice" and voice_data:
            analysis["voice_integration"] = {
                "weight_multiplier": self.core.voice_weight_multiplier,
                "audio_duration": voice_data.get("duration", 0),
                "confidence_score": voice_data.get("confidence", 0.5),
                "transcription_quality": voice_data.get("quality", "medium"),
            }

        # TaskMasteré€£æºæƒ…å ±
        if task_context:
            analysis["task_integration"] = {
                "task_id": task_context.get("task_id"),
                "task_title": task_context.get("title"),
                "completion_status": task_context.get("status"),
                "learning_correlation": self._calculate_task_learning_correlation(
                    analysis["suetake_likeness_index"], task_context
                ),
            }

        return enhanced

    def _record_to_database(
        self, analysis_result: Dict, analysis_id: str, start_time: datetime
    ):
        """çµ±åˆåˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²"""

        analysis = analysis_result["analysis"]
        processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

        # 1. åˆ†æå±¥æ­´è¨˜éŒ²
        self.database.record_analysis(
            analysis_id=analysis_id,
            analysis_type="journal",
            input_text=analysis_result["content"],
            result={
                "suetake_likeness": analysis["suetake_likeness_index"],
                "tech_keywords": analysis["tech_keyword_count"],
                "integrity_keywords": analysis["integrity_keyword_count"],
                "insights": analysis["insights"],
            },
            confidence=analysis.get("confidence_score", 0.8),
            processing_time=processing_time,
        )

        # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å­¦ç¿’æ›´æ–°
        content = analysis_result["content"]
        for keyword in self.core.tech_keywords:
            if keyword in content:
                self.database.learn_keyword(
                    keyword=keyword,
                    category="technical",
                    context=f"Found in {analysis_result['source']} analysis",
                    sentiment=0.2,
                )

        for keyword in self.core.integrity_keywords:
            if keyword in content:
                self.database.learn_keyword(
                    keyword=keyword,
                    category="integrity",
                    context=f"Found in {analysis_result['source']} analysis",
                    sentiment=0.3,
                )

        # 3. ç²¾åº¦æ¸¬å®šè¨˜éŒ²
        if analysis["suetake_likeness_index"] > self.current_accuracy:
            self.database.record_accuracy_measurement(
                emotion=0.8,  # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                expression=0.85,  # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                value=analysis["suetake_likeness_index"] / 100.0,
                overall=analysis["suetake_likeness_index"] / 100.0,
                suggestions=f"çµ±åˆåˆ†æã«ã‚ˆã‚Šç²¾åº¦å‘ä¸Š: {analysis['suetake_likeness_index']}%",
            )

    def _check_evolution_progress(self, analysis_result: Dict) -> Dict[str, Any]:
        """ç²¾åº¦é€²åŒ–ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚§ãƒƒã‚¯"""

        current_score = analysis_result["analysis"]["suetake_likeness_index"]

        # é€²åŒ–æ®µéšåˆ¤å®š
        evolution_stage = self._get_evolution_stage(current_score)
        # progress_percentageã‚’100%ä»¥å†…ã«åˆ¶é™ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„å¯¾å¿œï¼‰
        progress_percentage = min((current_score / self.target_accuracy) * 100, 100.0)

        # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é”æˆåˆ¤å®š
        milestone_achieved = (
            current_score >= 90.0 and current_score > self.current_accuracy
        )

        if milestone_achieved:
            logger.info(f"ğŸ‰ ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³é”æˆ! ç²¾åº¦: {current_score}%")

        # å­¦ç¿’é€²æ—è¨˜éŒ²ï¼ˆåˆ¶ç´„å¯¾å¿œ: currentå€¤ã‚‚1.0ä»¥å†…ã«åˆ¶é™ï¼‰
        self.database.record_learning_progress(
            phase=evolution_stage,
            target=self.target_accuracy / 100.0,
            current=min(current_score / 100.0, 1.0),  # 1.0ä»¥å†…ã«åˆ¶é™
            method="integrated_mirralism_analysis",
            notes=f"çµ±åˆåˆ†æã«ã‚ˆã‚‹é€²æ—: {current_score}% â†’ ç›®æ¨™: {self.target_accuracy}%",
        )

        # ç²¾åº¦æ›´æ–°
        if current_score > self.current_accuracy:
            self.current_accuracy = current_score
            self.core.update_learning_accuracy(current_score)

        return {
            "evolution_stage": evolution_stage,
            "progress_percentage": progress_percentage,
            "milestone_achieved": milestone_achieved,
            "accuracy_improved": current_score > self.current_accuracy,
            "current_accuracy": self.current_accuracy,
            "target_accuracy": self.target_accuracy,
        }

    def _get_evolution_stage(self, accuracy: float) -> str:
        """ç²¾åº¦ã«åŸºã¥ãé€²åŒ–æ®µéšå–å¾—"""
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¶ç´„ã«æº–æ‹ ã—ãŸãƒ•ã‚§ãƒ¼ã‚ºåã«ãƒãƒƒãƒ”ãƒ³ã‚°
        evolution_mapping = {
            53.0: "initial",  # V1_baseline
            61.0: "initial",  # V1_learned
            70.0: "training",  # V2_training
            80.0: "validation",  # V2_validation
            90.0: "production",  # V2_production_ready
            95.0: "production",  # V2_target_achieved
        }

        # ``dict_items`` does not guarantee ``reversed`` support on all
        # Python versions.  Sort the thresholds explicitly in descending
        # order so the function behaves consistently on Python 3.9+.
        for threshold, stage in sorted(
            evolution_mapping.items(), key=lambda x: x[0], reverse=True
        ):
            if accuracy >= threshold:
                return stage
        return "initial"

    def _calculate_task_learning_correlation(
        self, accuracy: float, task_context: Dict
    ) -> float:
        """TaskMasteré€£æº: ã‚¿ã‚¹ã‚¯å®Œäº†ã¨å­¦ç¿’åŠ¹æœã®ç›¸é–¢è¨ˆç®—"""

        base_correlation = 0.5

        # ã‚¿ã‚¹ã‚¯ç¨®åˆ¥ã«ã‚ˆã‚‹å­¦ç¿’å½±éŸ¿åº¦
        task_title = task_context.get("title", "").lower()

        if "personality" in task_title or "learning" in task_title:
            base_correlation += 0.3
        elif "database" in task_title or "integration" in task_title:
            base_correlation += 0.2
        elif "mirralism" in task_title or "v2" in task_title:
            base_correlation += 0.25

        # ç²¾åº¦ã«ã‚ˆã‚‹è£œæ­£
        accuracy_factor = (accuracy - 50.0) / 50.0  # 50%ã‚’åŸºæº–ã¨ã—ãŸæ­£è¦åŒ–

        return min(base_correlation + accuracy_factor * 0.2, 1.0)

    def correlate_with_task(
        self,
        task_id: int,
        task_title: str,
        task_status: str,
        learning_elements: int = 0,
    ) -> bool:
        """TaskMasteré€£æº: ã‚¿ã‚¹ã‚¯å®Œäº†ã¨å­¦ç¿’åŠ¹æœã®ç›¸é–¢è¨˜éŒ²"""

        try:
            # å­¦ç¿’å½±éŸ¿åº¦è¨ˆç®—
            learning_impact = self._calculate_task_learning_correlation(
                self.current_accuracy,
                {"title": task_title, "status": task_status},
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²
            self.database.correlate_task_learning(
                task_id=task_id,
                task_title=task_title,
                learning_impact=learning_impact,
                elements_discovered=learning_elements,
                accuracy_before=self.current_accuracy,
                accuracy_after=self.current_accuracy,  # å®Ÿåˆ†æå¾Œã«æ›´æ–°
            )

            logger.info(f"TaskMasteré€£æºè¨˜éŒ²: Task {task_id}, å­¦ç¿’å½±éŸ¿åº¦: {learning_impact}")
            return True

        except Exception as e:
            logger.error(f"TaskMasteré€£æºã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def register_voice_analysis(
        self,
        file_path: str,
        transcription: str,
        duration: float,
        confidence: float = 0.8,
    ) -> Optional[int]:
        """SuperWhisperçµ±åˆ: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç™»éŒ²"""

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²
            voice_id = self.database.register_voice_data(
                file_path=file_path,
                file_name=os.path.basename(file_path),
                duration=duration,
                transcription=transcription,
                confidence=confidence,
            )

            logger.info(f"SuperWhisperéŸ³å£°ãƒ‡ãƒ¼ã‚¿ç™»éŒ²: {file_path}, ID: {voice_id}")
            return voice_id

        except Exception as e:
            logger.error(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def get_evolution_status(self) -> Dict[str, Any]:
        """53%â†’95%é€²åŒ–çŠ¶æ³å–å¾—"""

        return {
            "current_accuracy": self.current_accuracy,
            "target_accuracy": self.target_accuracy,
            "progress_percentage": (self.current_accuracy / self.target_accuracy) * 100,
            "evolution_stage": self._get_evolution_stage(self.current_accuracy),
            "accuracy_gap": self.target_accuracy - self.current_accuracy,
            "database_status": self.database.get_learning_stats(),
            "version": self.version,
        }

    def get_system_health(self) -> Dict[str, Any]:
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""

        try:
            core_status = self.core.get_system_status()
            db_stats = self.database.get_learning_stats()
            evolution_status = self.get_evolution_status()

            return {
                "system_healthy": True,
                "core_system": core_status,
                "database_stats": db_stats,
                "evolution_progress": evolution_status,
                "integration_level": "full",
                "version": self.version,
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "system_healthy": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    def close(self):
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ çµ‚äº†å‡¦ç†"""
        if hasattr(self, "database"):
            self.database.close()
        logger.info("MIRRALISMçµ±åˆã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
_mirralism_instance = None


def get_mirralism_system(
    db_path: Optional[str] = None,
) -> MirralismPersonalityLearning:
    """MIRRALISMã‚·ã‚¹ãƒ†ãƒ ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—"""
    global _mirralism_instance

    if _mirralism_instance is None:
        _mirralism_instance = MirralismPersonalityLearning(db_path)

    return _mirralism_instance


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
if __name__ == "__main__":
    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
    system = get_mirralism_system()

    print("ğŸš€ MIRRALISMçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)

    # åŸºæœ¬åˆ†æãƒ†ã‚¹ãƒˆ
    test_content = """
    MIRRALISM V2ã®çµ±åˆé–‹ç™ºãŒé †èª¿ã«é€²ã‚“ã§ã„ã¾ã™ã€‚
    PersonalityLearningã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ã«ã‚ˆã‚Šã€
    æŠ€è¡“çš„ãªèª²é¡Œè§£æ±ºã¨å“è³ªå‘ä¸Šã‚’å®Ÿç¾ã§ãã¦ã„ã¾ã™ã€‚
    """

    result = system.analyze_entry(content=test_content, source_type="journal")

    print(f"âœ… åˆ†æçµæœ: {result['analysis']['suetake_likeness_index']}%")
    print(f"ğŸ“Š é€²åŒ–çŠ¶æ³: {result['evolution_status']['evolution_stage']}")

    # ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    health = system.get_system_health()
    print(f"ğŸ’š ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§: {health['system_healthy']}")

    print("\nğŸ‰ MIRRALISMçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†!")

    system.close()
